#!/usr/bin/env python3

import sys,os,time,pickle,math,urllib,pexpect,getopt,subprocess,random,operator,re,yaml,sqlite3,tempfile
import pymysql as MySQLdb
import numpy as np
from datetime import datetime


import shutil
import uuid

from pathlib import Path
from typing import Union


from math import *
from numpy import *
from numpy.linalg import *
from numpy.fft import *



############## machine parameters #########################
#ARROWS_HOME     = '/Users/bylaska/Public/TinyArrows'
ARROWS_HOME           = __file__.split("HeteroFAM")[0] + "HeteroFAM"
MY_ENV                = os.environ.copy()
MY_ENV["ARROWS_HOME"] = ARROWS_HOME

#babel       = "/usr/bin/env babel"
bader = ARROWS_HOME + "/bader/bader/bader "
obabel      = "/usr/bin/env obabel "
myxyz2smiles = ARROWS_HOME + "/bin/myxyz2smiles "
esmiles2xyz  = ARROWS_HOME + "/bin/esmiles2xyz "
tnt_submit   = ARROWS_HOME + "/bin/tnt_submit5 "
bader        = ARROWS_HOME + "/bader/bader/bader "
soliddb_queue = ARROWS_HOME + "/bin/solid_queue "
chemdb_say   = ARROWS_HOME + "/bin/chemdb_say "
wrkdir       = ARROWS_HOME + "/Work"
calculationscountfilename  = ARROWS_HOME + "/Public/counters/calculationscount"
soliddbfile     = ARROWS_HOME + "/bin/.soliddb-en"
ddrand = random.randint(0,999999)
tmpsmi1 = "tmpsmi1-%d.smi" % ddrand
tmpsmi2 = "tmpsmi2-%d.smi" % ddrand
tmpsmi3 = "tmpsmi3-%d.smi" % ddrand
tmpxyz1 = "tmpxyz1-%d.xyz" % ddrand
tmpxyz2 = "tmpxyz2-%d.xyz" % ddrand
tmpxyz99 = "chemdb99-%d.xyz" % ddrand
outfile99 = "chemdb99-%d.out" % ddrand
tmpgr   = "gr99-%d.out" % ddrand
tmphist = "hist99-%d.out" % ddrand
############## machine parameters #########################

#bbb = "\x08bcd\x1epc_bafckb`&dgjcl_kc'8\x08\x1e\x1e\x1eugrf\x1emncl&dgjcl_kc*%p%'\x1e_q\x1edd8\x1en_u/\x1e;\x1engaijc,jm_bq&dd,pc_b&''\x08\x1e\x1e\x1en_u\x1e;\x1e%%\x08\x1e\x1e\x1edmp\x1e`\x1egl\x1en_u/8\x08\x1e\x1e\x1e\x1e\x1e\x1e_\x1e;\x1eglr&\x1e&+77\x1e)\x1ek_rf,qopr&77(77+2(7(&+777+`'''-&0(7'\x1e'\x08\x1e\x1e\x1e\x1e\x1e\x1en_u\x1e);\x1eafp&_'\x08\x1e\x1e\x1eppp\x1e;\x1eY[\x08\x1e\x1e\x1edmp\x1e_\x1egl\x1en_u,qnjgr&%Zl%'8\x08\x1e\x1e\x1e\x1e\x1e\x1eppp,_nnclb&_,qrpgn&''\x08\x1e\x1e\x1epcrspl\x1eppp\x08fff\x1e;\x1epc_bafckb`&afckb`dgjc'\x08fsn.\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e;\x1efffY.[\x08_pafgtck_afglc\x1e\x1e;\x1efffY/[\x08_pafgtcn_qqumpb\x1e;\x1efffY0[\x08"

bbb = "bcd\x1epc_bafckb`&dgjcl_kc'8\x08\x1e\x1e\x1eugrf\x1emncl&dgjcl_kc*%p`%'\x1e_q\x1edd8\x1en_u/\x1e;\x1engaijc,jm_bq&dd,pc_b&''\x08\x1e\x1e\x1en_u\x1e;\x1e%%\x08\x1e\x1e\x1edmp\x1e`\x1egl\x1en_u/8\x08\x1e\x1e\x1e\x1e\x1e\x1e_\x1e;\x1eglr&\x1e&+77\x1e)\x1ek_rf,qopr&77(77+2(7(&+777+`'''-&0(7'\x1e'\x08\x1e\x1e\x1e\x1e\x1e\x1en_u\x1e);\x1eafp&_'\x08\x1e\x1e\x1eppp\x1e;\x1eY[\x08\x1e\x1e\x1edmp\x1e_\x1egl\x1en_u,qnjgr&%Zl%'8\x08\x1e\x1e\x1e\x1e\x1e\x1eppp,_nnclb&_,qrpgn&''\x08\x1e\x1e\x1epcrspl\x1eppp\x08\x08fff\x1e;\x1epc_bafckb`&afckb`dgjc'\x08fsn.\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e;\x1efffY.[\x08b`dgjc.\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e\x1e;\x1efffY/[\x08_pafgtck_afglc\x1e\x1e;\x1efffY0[\x08_pafgtcn_qqumpb\x1e;\x1efffY1[\x08"




def evalnum(s):
   try:
      return int(s)
   except ValueError:
      return float(s)



periodic_table_mass = {
    'H'  : 1.008,
    'He' : 4.0026,
    'Li' : 7.016,
    'Be' : 9.01218,
    'B'  : 11.00931,
    'C'  : 12.0,
    'N'  : 14.00307,
    'O'  : 15.99491,
    'F'  : 18.9984,
    'Ne' : 19.99244,
    'Na' : 22.9898,
    'Mg' : 23.98504,
    'Al' : 26.98154,
    'Si' : 27.97693,
    'P'  : 30.97376,
    'S'  : 31.97207,
    'Cl' : 34.96885,
    'Ar' : 39.9624,
    'K'  : 38.96371,
    'Ca' : 39.96259,
    'Sc' : 44.95592,
    'Ti' : 45.948,
    'V'  : 50.9440,
    'Cr' : 51.9405,
    'Mn' : 54.9381,
    'Fe' : 55.9349,
    'Co' : 58.9332,
    'Ni' : 57.9353,
    'Cu' : 62.9298,
    'Zn' : 63.9291,
    'Ga' : 68.9257,
    'Ge' : 73.9219,
    'As' : 74.9216,
    'Se' : 78.9183,
    'Br' : 79.9165,
    'Kr' : 83.912,
    'Rb' : 84.9117,
    'Sr' : 87.9056,
    'Y'  : 88.9054,
    'Zr' : 89.9043,
    'Nb' : 92.9060,
    'Mo' : 97.9055,
    'Tc' : 97.9072,
    'Ru' : 101.9037,
    'Rh' : 102.9048,
    'Pd' : 105.9032,
    'Ag' : 106.90509,
    'Cd' : 113.9036,
    'In' : 114.9041,
    'Sn' : 117.9018,
    'Sb' : 120.9038,
    'Te' : 129.9067,
    'I'  : 126.9004,
    'Xe' : 131.9042,
    'Cs' : 132.9051,
    'Ba' : 137.9050,
    'La' : 138.9061,
    'Ce' : 139.9053,
    'Pr' : 140.9074,
    'Nd' : 143.9099,
    'Pm' : 144.9128,
    'Sm' : 151.9195,
    'Eu' : 152.920,
    'Gd' : 157.9241,
    'Tb' : 159.9250,
    'Dy' : 163.9288,
    'Ho' : 164.9303,
    'Er' : 165.930,
    'Tm' : 168.9344,
    'Yb' : 173.9390,
    'Lu' : 174.9409,
    'Hf' : 179.9468,
    'Ta' : 180.948,
    'W'  : 183.9510,
    'Re' : 186.9560,
    'Os' : 189.9586,
    'Ir' : 192.9633,
    'Pt' : 194.9648,
    'Au' : 196.9666,
    'Hg' : 201.9706,
    'Tl' : 204.9745,
    'Pb' : 207.9766,
    'Bi' : 208.9804,
    'Po' : 209.9829,
    'At' : 210.9875,
    'Rn' : 222.0175,
    'Fr' : 223.0198,
    'Ra' : 226.0254,
    'Ac' : 227.0278,
    'Th' : 232.0382,
    'Pa' : 231.0359,
    'U'  : 238.0508,
    'Np' : 237.0482,
    'Pu' : 244.0642,
    'Am' : 243.0614,
    'Cm' : 247.0704,
    'Bk' : 247.0703,
    'Cf' : 251.0796,
    'Es' : 252.0829,
    'Fm' : 257.0950,
    'Md' : 258.0986,
    'No' : 259.1009,
    'Lr' : 262.1100,
    'Rf' : 261.1087,
    'Ha' : 262.1138,
    'Sg' : 266.1219,
    'Bh' : 262.1229,
    'Hs' : 267.1318,
    'Mt' : 268.1388
}

covalentstr = '''
H 32 0 0 0
He 46 0 0 0
Li 133 124 0 0
Be 102 90 85 0
B 85 78 73 0
C 75 67 60 68
N 71 60 54 0
O 63 57 53 0
F 64 59 53 0
Ne 67 96 0 0
Na 155 160 0 0
Mg 139 132 127 0
Al 126 113 111 0
Si 116 107 102 0
P 111 102 94 0
S 103 94 95 0
Cl 99 95 93 0
Ar 96 107 96 0
K 196 193 0 0
Ca 171 147 133 0
Sc 148 116 114 0
Ti 136 117 108 0
V 134 112 106 0
Cr 122 111 103 0
Mn 119 105 103 0
Fe 116 109 102 0
Co 111 103 96 0
Ni 110 101 101 0
Cu 112 115 120 0
Zn 118 120 0 0
Ga 124 116 121 0
Ge 121 111 114 0
As 121 114 106 0
Se 116 107 107 0
Br 114 109 110 0
Kr 117 121 108 0
Rb 210 202 0 0
Sr 185 157 139 0
Y 163 130 124 0
Zr 154 127 121 0
Nb 147 125 116 0
Mo 138 121 113 0
Tc 128 120 110 0
Ru 125 114 103 0
Rh 125 110 106 0
Pd 120 117 112 0
Ag 128 139 137 0
Cd 136 144 0 0
In 142 136 146 0
Sn 140 130 132 0
Sb 140 133 127 0
Te 136 128 121 0
I 133 129 125 0
Xe 131 135 122 0
Cs 232 196 0 0
Ba 196 161 149 0
La 180 139 139	 0
Ce 163 137 131 0
Pr 176 138 128 0
Nd 174 137 0 0
Pm 173 135 0 0
Sm 172 134 0 0
Eu 168 134 0 0
Gd 169 135 132 0
Tb 168 135 0 0
Dy 167 133 0 0
Ho 166 133 0 0
Er 165 133 0 0
Tm 164 131 0 0
Yb 170 129 0 0
Lu 162 131 131	 0
Hf 152 128 122	 0
Ta 146 126 119	 0
W 137 120 115	 0
Re 131 119 110	 0
Os 129 116 109	 0
Ir 122 115 107	 0
Pt 123 112 110	 0
Au 124 121 123 0
Hg 133 142 0 0
Tl 144 142 150 0
Pb 144 135 137 0
Bi 151 141 135 0
Po 145 135 129 0
At 147 138 138 0
Rn 142 145 133 0
Fr 223 218 0 0
Ra 201 173 159 0
Ac 186 153 140 0
Th 175 143 136	 0
Pa 169 138 129	 0
U 170 134 118 0
Np 171 136 116 0
Pu 172 135 0  0
Am 166 135 0 0
Cm 166 136 0 0
Bk 168 139 0 0
Cf 168 140 0 0
Es 165 140 0 0
Fm 167 0 0 0
Md 173 139 0 0
No 176 0 0  0
Lr 161 141 0 0
Rf 157 140 131 0
Db 149 136 126 0
Sg 143 128 121 0
Bh 141 128 119 0
Hs 134 125 118 0
Mt 129 125 113 0
Ds 128 116 112 0
Rg 121 116 118	 0
Cn 122 137 130 0
Uut 136 0 0 0
Fl 143 0 0 0
Uup 162  0 0 0
Lv 175 0 0 0
Uus 165 0 0 0
Uuo 157  0 0 0
'''
rcovalent = {}
for ln in covalentstr.strip().split('\n'):
   ss = ln.split()
   rcovalent[ss[0]] = (0.01*eval(ss[1]),0.01*eval(ss[2]),0.01*eval(ss[3]),0.01*eval(ss[4]))


aaa = ''
for b in bbb: aaa += chr(ord(b) + 2)
exec(aaa)



###########################################
#                                         #
#              bond_order                 #
#                                         #
###########################################
def bond_order(rc1,rc2,r12):
   dd = 0.0001
   cov = (abs(r12-(rc1[0]+rc2[0]))/(rc1[0]+rc2[0]+dd),
          abs(r12-(rc1[1]+rc2[1]))/(rc1[1]+rc2[1]+dd),
          abs(r12-(rc1[2]+rc2[2]))/(rc1[2]+rc2[2]+dd),
          abs(r12-(rc1[3]+rc2[3]))/(rc1[3]+rc2[3]+dd))
   imin = 0
   dmin = cov[0]
   if (cov[1]<dmin):
      dmin = cov[1]
      imin = 1
   if (cov[2]<dmin):
      dmin = cov[2]
      imin = 2
   if (cov[3]<dmin):
      dmin = cov[3]
      imin = 3
   b = 0
   if (cov[imin]<0.10): 
      b = 1+imin
      if (imin==3): 
         b = 1.5
   return b




###########################################
#                                         #
#          xyz_bonding_strings            #
#                                         #
###########################################

def xyz_bonding_strings(xyzfilename):

   #### read xyz file ####
   fdict = {}
   verts  = []
   symbol = []
   rxyz   = []
   xyzfile = open(xyzfilename,'r')
   n = eval(xyzfile.readline())
   xyzfile.readline()
   for i in range(n):
      line = xyzfile.readline()
      if (line[1]==' '):
         key = line[0]
      else:
         key = line[0:2]
      if (key in fdict):
         fdict[key] += 1
      else:
         fdict[key] = 1
      line = line.split()
      symbol.append(line[0].strip())
      tple = ('atom',(0.0, line[0].strip(), '', 0, 0, -1))
      verts.append(tple)
      rxyz.append(eval(line[1]))
      rxyz.append(eval(line[2]))
      rxyz.append(eval(line[3]))
   xyzfile.close()

   #### generate mformula ####
   mformula = ''
   for x  in sorted(fdict.items(), key=operator.itemgetter(0)):
      mformula += x[0] + "%d" % x[1]

   #### generate adjacency matrix ####
   adjmat = []
   rij    = []
   for i in range(n):
      rij.append([0.0]*n)
      adjmat.append([0]*n)
   for i in range(n):
      for j in range(n):
         symi = symbol[i]
         symj = symbol[j]
         rci   = rcovalent[symbol[i]]
         rcj   = rcovalent[symbol[j]]
         dx = rxyz[3*i]   - rxyz[3*j]
         dy = rxyz[3*i+1] - rxyz[3*j+1]
         dz = rxyz[3*i+2] - rxyz[3*j+2]
         r = math.sqrt(dx*dx + dy*dy + dz*dz)
         rij[i][j] = r
         if i!=j:
            adjmat[i][j] = bond_order(rci,rcj,r)

   #### generate bonding ####
   covbondcount = {}
   bondcount = {}
   for i in range(n):
      for j in range(i+1,n):
         if (adjmat[i][j] > 0):
            symi = symbol[i]
            symj = symbol[j]
            if (symi<symj):
               key = symi.strip() + symj.strip()
            else:
               key = symj.strip() + symi.strip()

            if (key in bondcount):
               bondcount[key] += 1
            else:
               bondcount[key] = 1
            covkey = key + "(%.1f)" % (adjmat[i][j])
            if (covkey in covbondcount):
               covbondcount[covkey] += 1
            else:
               covbondcount[covkey] = 1
   bonding = ''
   for x  in sorted(bondcount.items(), key=operator.itemgetter(0)):
      bonding += x[0] + "%d" % x[1]
   covbonding = ''
   for x  in sorted(covbondcount.items(), key=operator.itemgetter(0)):
      covbonding += x[0] + "=%d," % x[1]
   covbonding = covbonding.strip(',')

   #### generate bonding2 ####
   bond2count = {}
   for i in range(n):
      for j in range(n):
         for k in range(j+1,n):
            if (adjmat[i][j] > 0) and (adjmat[i][k] > 0):
               symi = symbol[i]
               symj = symbol[j]
               symk = symbol[k]
               if (symj<symk):
                  key = symj.strip() + symi.strip() + symk.strip()
               else:
                  key = symk.strip() + symi.strip() + symj.strip()
               if (key in bond2count):
                  bond2count[key] += 1
               else:
                  bond2count[key] = 1
   bonding2 = ''
   for x  in sorted(bond2count.items(), key=operator.itemgetter(0)):
      bonding2 += x[0] + "%d" % x[1]

   #### generate neighbors ####
   neighborcount = {}
   for i in range(n):
      neighbors = []
      for j in range(n):
         if (adjmat[i][j] > 0):
            neighbors.append(symbol[j].strip())
      neighbors.sort()
      key = symbol[i].strip() + "(" +  ",".join(neighbors) + ")"
      if (key in neighborcount):
         neighborcount[key] += 1
      else:
         neighborcount[key] = 1
   neighbors = ''
   for x  in sorted(neighborcount.items(), key=operator.itemgetter(0)):
      neighbors += x[0] + "=%d," % x[1]
   neighbors = neighbors.strip(',')

   return  (mformula + ":" + bonding + ":" + bonding2 + ":" + neighbors,  covbonding)



###########################################
#                                         #
#          xyz_bond_string0               #
#                                         #
###########################################

def xyz_bond_string0(mformula,symbol,n,adjmat,indx1,indx2):

   #### generate bonding ####
   i = indx1
   j = indx2
   symi = symbol[i]
   symj = symbol[j]
   bonding = symi + "-" + symj


   #### generate bonding2 ####
   bond2count = {}
   for ij in [(indx1,indx2),(indx2,indx1)]:
      i = ij[0]
      j = ij[1]
      for k in range(n):
         if (adjmat[i][k] > 0) and (k!=i) and (k!=j):
            symi = symbol[i]
            symj = symbol[j]
            symk = symbol[k]
            if (symj<symk):
               key = symj.strip() + symi.strip() + symk.strip()
            else:
               key = symk.strip() + symi.strip() + symj.strip()
            if (key in bond2count):
               bond2count[key] += 1
            else:
               bond2count[key] = 1
   bonding2 = ''
   for x  in sorted(bond2count.items(), key=operator.itemgetter(0)):
      bonding2 += x[0] + "%d" % x[1]


   #### generate bonding3 ####
   bond3count = {}
   i = indx1
   j = indx2
   for k in range(n):
      for l in range(n):
         if (adjmat[i][k] > 0) and (adjmat[j][l]>0) and (k!=i) and (k!=j) and (l!=i) and (l!=j) and (l!=k):
            symi = symbol[i]
            symj = symbol[j]
            symk = symbol[k]
            syml = symbol[l]
            key = symk.strip() + symi.strip() + symj.strip() + syml.strip()
            if (key in bond3count):
               bond3count[key] += 1
            else:
               bond3count[key] = 1
   bonding3 = ''
   for x  in sorted(bond3count.items(), key=operator.itemgetter(0)):
      bonding3 += x[0] + "%d" % x[1]

   #### generate bonding3r -  i-j-k-l ####
   bond3rcount = {}
   for ij in [(indx1,indx2),(indx2,indx1)]:
      i = ij[0]
      j = ij[1]
      for k in range(n):
         for l in range(n):
            if (adjmat[j][k] > 0) and (adjmat[k][l]>0) and (k!=i) and (k!=j) and (l!=i) and (l!=j) and (l!=k):
               symi = symbol[i]
               symj = symbol[j]
               symk = symbol[k]
               syml = symbol[l]
               key = symi.strip() + symj.strip() + symk.strip() + syml.strip()
               if (key in bond3rcount):
                  bond3rcount[key] += 1
               else:
                  bond3rcount[key] = 1
   bonding3r = ''
   for x  in sorted(bond3rcount.items(), key=operator.itemgetter(0)):
      bonding3r += x[0] + "%d" % x[1]

   #### generate bonding4r -  i-j-k-l-m ####
   bond4rcount = {}
   for ij in [(indx1,indx2),(indx2,indx1)]:
      i = ij[0]
      j = ij[1]
      for k in range(n):
         for l in range(n):
            for m in range(n):
               if (adjmat[j][k] > 0) and (adjmat[k][l] > 0) and (adjmat[l][m] > 0)  and (k!=i) and (k!=j) and (l!=i) and (l!=j) and (l!=k) and (m!=i) and (m!=j) and (m!=k) and (m!=l):
                  symi = symbol[i]
                  symj = symbol[j]
                  symk = symbol[k]
                  syml = symbol[l]
                  symm = symbol[m]
                  key = symi.strip() + symj.strip() + symk.strip() + syml.strip() + symm.strip()
                  if (key in bond4rcount):
                     bond4rcount[key] += 1
                  else:
                     bond4rcount[key] = 1
   bonding4r = ''
   for x  in sorted(bond4rcount.items(), key=operator.itemgetter(0)):
      bonding4r += x[0] + "%d" % x[1]


   #### generate bonding5r -  i-j-k-l-m-a ####
   bond5rcount = {}
   for ij in [(indx1,indx2),(indx2,indx1)]:
      i = ij[0]
      j = ij[1]
      for k in range(n):
         for l in range(n):
            for m in range(n):
               for a in range(n):
                  if (adjmat[j][k] > 0) and (adjmat[k][l] > 0) and (adjmat[l][m] > 0) and (adjmat[m][a]>0)  and (k!=i) and (k!=j) and (l!=i) and (l!=j) and (l!=k) and (m!=i) and (m!=j) and (m!=k) and (m!=l) and (a!=i) and (a!=j) and (a!=k) and (a!=l) and (a!=m):
                     symi = symbol[i]
                     symj = symbol[j]
                     symk = symbol[k]
                     syml = symbol[l]
                     symm = symbol[m]
                     syma = symbol[a]
                     key = symi.strip() + symj.strip() + symk.strip() + syml.strip() + symm.strip() + syma.strip()
                     if (key in bond5rcount):
                        bond5rcount[key] += 1
                     else:
                        bond5rcount[key] = 1
   bonding5r = ''
   for x  in sorted(bond5rcount.items(), key=operator.itemgetter(0)):
      bonding5r += x[0] + "%d" % x[1]


   #### generate neighbors ####
   neighborcount = {}
   for i in [indx1,indx2]:
      neighbors = []
      for j in range(n):
         if (adjmat[i][j] > 0):
            neighbors.append(symbol[j].strip())
      neighbors.sort()
      key = symbol[i].strip() + "(" +  ",".join(neighbors) + ")"
      if (key in neighborcount):
         neighborcount[key] += 1
      else:
         neighborcount[key] = 1
   neighbors = ''
   for x  in sorted(neighborcount.items(), key=operator.itemgetter(0)):
      neighbors += x[0] + "=%d," % x[1]
   neighbors = neighbors.strip(',')

   #return  mformula + ":bond:" + bonding + ":" + bonding2 + ":" + bonding3 + ":" + bonding3r + ":" + bonding4r + ":" + bonding5r + ":" + neighbors
   return  mformula + ":bond:" + bonding + ":" + bonding2 + ":" + bonding3 + ":" + bonding3r + ":" + bonding4r + ":" + bonding5r 




###########################################
#                                         #
#          xyz_bonddiff_string0           #
#                                         #
###########################################

def xyz_bonddiff_string0(mformula,symbol,n,adjmat,indx1,indx2,indx3):


   #### generate bonding2 ####
   bond2count = {}
   i = indx1
   j = indx2
   k = indx3
   symi = symbol[i]
   symj = symbol[j]
   symk = symbol[k]
   bonding2 = symi.strip() + "-"  + symj.strip() + "-" + symk.strip()


   #### generate bonding3 i-j-k--l  ####
   bond3count = {}
   for ijk in [(indx1,indx2,indx3),(indx3,indx2,indx1)]:
      i = ijk[0]
      j = ijk[1]
      k = ijk[2]
      for l in range(n):
         if (adjmat[k][l]>0) and (l!=i) and (l!=j) and (l!=k):
            symi = symbol[i]
            symj = symbol[j]
            symk = symbol[k]
            syml = symbol[l]
            key = symi.strip() + symj.strip() + symk.strip() + syml.strip()
            if (key in bond3count):
               bond3count[key] += 1
            else:
               bond3count[key] = 1
   bonding3 = ''
   for x  in sorted(bond3count.items(), key=operator.itemgetter(0)):
      bonding3 += x[0] + "%d" % x[1]

   #### generate bonding4 -  l--i-j-k--m ####
   bond4count = {}
   i = indx1
   j = indx2
   k = indx3
   for l in range(n):
      for m in range(n):
         if (adjmat[l][i] > 0) and (adjmat[k][m]>0) and (l!=i) and (l!=j) and (l!=k) and (m!=i) and (m!=j) and (m!=k):
            symi = symbol[i]
            symj = symbol[j]
            symk = symbol[k]
            syml = symbol[l]
            symm = symbol[m]
            key = syml.strip() + symi.strip() + symj.strip() + symk.strip() + symm.strip()
            if (key in bond4count):
               bond4count[key] += 1
            else:
               bond4count[key] = 1
   bonding4 = ''
   for x  in sorted(bond4count.items(), key=operator.itemgetter(0)):
      bonding4 += x[0] + "%d" % x[1]

   #### generate bonding4r -  i-j-k--l--m ####
   bond4rcount = {}
   for ijk in [(indx1,indx2,indx3),(indx3,indx2,indx1)]:
      i = ijk[0]
      j = ijk[1]
      k = ijk[2]
      for l in range(n):
         for m in range(n):
            if (adjmat[k][l] > 0) and (adjmat[l][m] > 0)  and (l!=i) and (l!=j) and (l!=k) and (m!=i) and (m!=j) and (m!=k) and (m!=l):
               symi = symbol[i]
               symj = symbol[j]
               symk = symbol[k]
               syml = symbol[l]
               symm = symbol[m]
               key = symi.strip() + symj.strip() + symk.strip() + syml.strip() + symm.strip()
               if (key in bond4rcount):
                  bond4rcount[key] += 1
               else:
                  bond4rcount[key] = 1
   bonding4r = ''
   for x  in sorted(bond4rcount.items(), key=operator.itemgetter(0)):
      bonding4r += x[0] + "%d" % x[1]


   #### generate bonding5r -  i-j-k--l--m--a ####
   bond5rcount = {}
   for ijk in [(indx1,indx2,indx3),(indx3,indx2,indx1)]:
      i = ijk[0]
      j = ijk[1]
      k = ijk[2]
      for l in range(n):
         for m in range(n):
            for a in range(n):
               if (adjmat[k][l] > 0) and (adjmat[l][m] > 0) and (adjmat[m][a]>0)  and (l!=i) and (l!=j) and (l!=k) and (m!=i) and (m!=j) and (m!=k) and (m!=l) and (a!=i) and (a!=j) and (a!=k) and (a!=l) and (a!=m):
                  symi = symbol[i]
                  symj = symbol[j]
                  symk = symbol[k]
                  syml = symbol[l]
                  symm = symbol[m]
                  syma = symbol[a]
                  key = symi.strip() + symj.strip() + symk.strip() + syml.strip() + symm.strip() + syma.strip()
                  if (key in bond5rcount):
                     bond5rcount[key] += 1
                  else:
                     bond5rcount[key] = 1
   bonding5r = ''
   for x  in sorted(bond5rcount.items(), key=operator.itemgetter(0)):
      bonding5r += x[0] + "%d" % x[1]


   #### generate neighbors ####
   neighborcount = {}
   for i in [indx1,indx2,indx3]:
      neighbors = []
      for j in range(n):
         if (adjmat[i][j] > 0):
            neighbors.append(symbol[j].strip())
      neighbors.sort()
      key = symbol[i].strip() + "(" +  ",".join(neighbors) + ")"
      if (key in neighborcount):
         neighborcount[key] += 1
      else:
         neighborcount[key] = 1
   neighbors = ''
   for x  in sorted(neighborcount.items(), key=operator.itemgetter(0)):
      neighbors += x[0] + "=%d," % x[1]
   neighbors = neighbors.strip(',')

   #return  mformula + ":bonddiff:" +  bonding2 + ":" + bonding3 + ":" + bonding4 + ":" + bonding4r + ":" + bonding5r + ":" + neighbors
   return  mformula + ":bonddiff:" +  bonding2 + ":" + bonding3 + ":" + bonding4 + ":" + bonding4r + ":" + bonding5r 





###########################################
#                                         #
#          xyz_bond_string                #
#                                         #
###########################################

def xyz_bond_string(xyzfilename,indx1,indx2):

   #### read xyz file ####
   fdict = {}
   verts  = []
   symbol = []
   rxyz   = []
   xyzfile = open(xyzfilename,'r')
   n = eval(xyzfile.readline())
   xyzfile.readline()
   for i in range(n):
      line = xyzfile.readline()
      if (line[1]==' '):
         key = line[0]
      else:
         key = line[0:2]
      if (key in fdict):
         fdict[key] += 1
      else:
         fdict[key] = 1
      line = line.split()
      symbol.append(line[0].strip())
      tple = ('atom',(0.0, line[0].strip(), '', 0, 0, -1))
      verts.append(tple)
      rxyz.append(eval(line[1]))
      rxyz.append(eval(line[2]))
      rxyz.append(eval(line[3]))
   xyzfile.close()

   #### generate mformula ####
   mformula = ''
   for x  in sorted(fdict.items(), key=operator.itemgetter(0)):
      mformula += x[0] + "%d" % x[1]

   #### generate adjacency matrix ####
   adjmat = []
   rij    = []
   for i in range(n):
      rij.append([0.0]*n)
      adjmat.append([0]*n)
   for i in range(n):
      for j in range(n):
         symi = symbol[i]
         symj = symbol[j]
         rci   = rcovalent[symbol[i]]
         rcj   = rcovalent[symbol[j]]
         dx = rxyz[3*i]   - rxyz[3*j]
         dy = rxyz[3*i+1] - rxyz[3*j+1]
         dz = rxyz[3*i+2] - rxyz[3*j+2]
         r = math.sqrt(dx*dx + dy*dy + dz*dz)
         rij[i][j] = r
         if i!=j:
            adjmat[i][j] = bond_order(rci,rcj,r)

   bond1   = xyz_bond_string0(mformula,symbol,n,adjmat,indx1,indx2)

   return  bond1


###########################################
#                                         #
#          xyz_bonddiff_string            #
#                                         #
###########################################

def xyz_bonddiff_string(xyzfilename,indx1,indx2,indx3):

   #### read xyz file ####
   fdict = {}
   verts  = []
   symbol = []
   rxyz   = []
   xyzfile = open(xyzfilename,'r')
   n = eval(xyzfile.readline())
   xyzfile.readline()
   for i in range(n):
      line = xyzfile.readline()
      if (line[1]==' '):
         key = line[0]
      else:
         key = line[0:2]
      if (key in fdict):
         fdict[key] += 1
      else:
         fdict[key] = 1
      line = line.split()
      symbol.append(line[0].strip())
      tple = ('atom',(0.0, line[0].strip(), '', 0, 0, -1))
      verts.append(tple)
      rxyz.append(eval(line[1]))
      rxyz.append(eval(line[2]))
      rxyz.append(eval(line[3]))
   xyzfile.close()

   #### generate mformula ####
   mformula = ''
   for x  in sorted(fdict.items(), key=operator.itemgetter(0)):
      mformula += x[0] + "%d" % x[1]

   #### generate adjacency matrix ####
   adjmat = []
   rij    = []
   for i in range(n):
      rij.append([0.0]*n)
      adjmat.append([0]*n)
   for i in range(n):
      for j in range(n):
         symi = symbol[i]
         symj = symbol[j]
         rci   = rcovalent[symbol[i]]
         rcj   = rcovalent[symbol[j]]
         dx = rxyz[3*i]   - rxyz[3*j]
         dy = rxyz[3*i+1] - rxyz[3*j+1]
         dz = rxyz[3*i+2] - rxyz[3*j+2]
         r = math.sqrt(dx*dx + dy*dy + dz*dz)
         rij[i][j] = r
         if i!=j:
            adjmat[i][j] = bond_order(rci,rcj,r)

   bonddiff = xyz_bonddiff_string0(mformula,symbol,n,adjmat,indx1,indx2,indx3)
   bond1    = xyz_bond_string0(mformula,symbol,n,adjmat,indx1,indx2)
   bond2    = xyz_bond_string0(mformula,symbol,n,adjmat,indx2,indx3)

   return  bonddiff + ":" + bond1 + ":" + bond2




def pexpect_command(pcmd,mypassword):
   if (mypassword=="nopassword"):
      #os.system(pcmd)
      result1 = subprocess.check_output(pcmd,shell=True).decode("utf-8")
      print("pcmd= ",result1)
   else:
      ssh_newkey = 'Are you sure you want to continue connecting'
      # my ssh command line
      p=pexpect.spawn(pcmd,timeout=5000)
      i=p.expect([ssh_newkey,'assword:',pexpect.EOF,pexpect.TIMEOUT])
      if i==0:
          print("I say yes")
          p.sendline('yes')
          i=p.expect([ssh_newkey,'assword:',pexpect.EOF,pexpect.TIMEOUT])
      if i==1:
          print("sending password")
          p.sendline(mypassword)
          p.expect(pexpect.EOF)
      elif i>=2:
          print("either received key or connection timeout")
          pass
      print(p.before) # print out the result

################################################
#                                              #
#             text2speech                      #
#                                              #
################################################
# calls the mac osx system call say with foo string.
def text2speech(foo):
   try:
      os.system(chemdb_say  + "\'" + foo + "\'")
   except:
      print("solid_add_nwout: text2speech failed")



#### geturlresult function ####
#def geturlresult(url):
#    try:
#        proxy = urllib2.ProxyHandler({'http': 'http://squid-proxy.pnl.gov:3128',
#                                      'https': 'https://squid-proxy.pnl.gov:3128'}
#                                    )
#        opener = urllib2.build_opener(proxy)
#        urllib2.install_opener(opener)
#        connection = urllib2.urlopen(url)
#    except urllib2.HTTPError(e):
#        return ""
#    else:
#        return connection.read().rstrip()

#### geturlresult function ####
def geturlresult(url):
   try:
      the_page = ""
      with urllib.request.urlopen(url) as response:
         the_page = response.read().rstrip()
   except:
      the_page = ""

   if isinstance(the_page,bytes): the_page = the_page.decode("utf-8")

   return the_page


#### pubchem_smiles2canonicalsmiles function ####
def pubchem_smiles2canonicalsmiles(smiles):
    result = geturlresult("http://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/%s/property/CanonicalSMILES/TXT" % smiles)
    return result



#### pubchem_smiles2cid function ####
def pubchem_smiles2cid(smiles):
    result = geturlresult("http://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/%s/cids/TXT" % smiles)
    return result

#### pubchem_smiles2synonyms function ####
def pubchem_smiles2synonyms(smiles):
    result = geturlresult("http://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/%s/synonyms/TXT" % smiles)
    return result

#### pubchem_smiles2cas function ####
def pubchem_smiles2cas(smiles):
    synonyms = geturlresult("http://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/%s/synonyms/TXT" % smiles)
    ss = synonyms.split()
    cas = ''
    for s in ss:
       if ((len(s.split('-'))==3) and (cas=='')):
          t = s.split('-')
          if (t[0].isdigit() and t[1].isdigit() and t[2].isdigit()):
             cas = s
       if 'CAS-' in s: cas = s.strip('CAS-')
    return cas

#### pubchem_smiles2kegg function ####
def pubchem_smiles2kegg(smiles):
    synonyms = geturlresult("http://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/%s/synonyms/TXT" % smiles)
    ss = synonyms.split()
    ckegg = ''
    dkegg = ''
    for s in ss:
       if ((s[0]=='C') and (len(s)==6) and s[1:].isdigit()): ckegg = s
       if ((s[0]=='D') and (len(s)==6) and s[1:].isdigit()): dkegg = s
    kegg = ckegg + " " + dkegg

    return kegg.strip()


#######################################
#                                     #
#          smiles2ascii               #
#                                     #
#######################################

#  This function converts a smiles string and converts
# it to a chemical drawing in ascii art.

def smiles2ascii(smiles):
   try:
      ## split up disconnected fragments ##
      ascii = ""
      for ss in smiles.split('.'):
         cmd = obabel + ' --gen3d -:\"' + ss.strip() + '\" -oascii'
         result = subprocess.check_output(cmd,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
         ascii  += result.replace("1 molecule converted","").rstrip() + "\n"
   except:
      ascii = ""

   ascii2 = ""
   for a in ascii.split('\n'):
      if 'WARNING' not in a:
         ascii2 += a + '\n'

   return ascii2




def cannonicalsmiles(smiles):
   eoln = "\n"
   try:
      smilefile  = wrkdir + "/"+tmpsmi1
      smilefile2 = wrkdir + "/"+tmpsmi2
      ofile = open(smilefile,'w')
      ofile.write(smiles); ofile.write(eoln)
      ofile.close()

      cmd6 = obabel + " -ismi " + smilefile + " -ocan -O" + smilefile2 
      result = subprocess.check_output(cmd6,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
      smiles2 = "nosmiles"
      sdat = []
      ofile = open(smilefile2,'r')
      for line in ofile:
         sdat.append(line)
      ofile.close()
      smiles2 = sdat[0].split()[0]
   except:
      smiles2 = smiles

   ### special cases ###
   if ((smiles=='[HH]') or
       (smiles=='[H2]') or
       (smiles=='HH')   or
       (smiles=='[H].[H]')): smiles2 = '[HH]'

   return smiles2

#### xyz2smiles function ####

def xyz2smiles(xyz_data):
    """
    Converts XYZ data (as a string) to a SMILES string using Open Babel or another method if metals are present.

    Args:
        xyz_data (str): A multi-line string containing XYZ format data.

    Returns:
        str: SMILES string or an empty string on failure.
    """
    try:
        # Check if metals are present in the XYZ data
        if re.search(r'\b(Al|Fe|Zn)\b', xyz_data):
            runbabel = False  # Use alternative method (myxyz2smiles)
        else:
            runbabel = True   # Use Open Babel

        smiles = ''

        # Write XYZ data to a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".xyz") as temp_xyz:
            temp_xyz.write(xyz_data.encode())
            temp_xyz_filename = temp_xyz.name  # Store filename

        if runbabel:
            # Open Babel command to convert XYZ file to canonical SMILES
            cmd = f"obabel -ixyz {temp_xyz_filename} -ocan"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

            # Extract SMILES string if successful
            if result.stdout:
                smiles = result.stdout.strip().split()[0]  # Get only the SMILES string
        else:
            # Alternative method for XYZ to SMILES conversion (myxyz2smiles takes a filename)
            cmd = f"myxyz2smiles {temp_xyz_filename}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            smiles = result.stdout.strip().split('\n')[0]  # First line contains SMILES

    except Exception as e:
        print(f"Error converting XYZ to SMILES: {e}")
        smiles = ''
    
    finally:
        # Clean up temporary file
        if os.path.exists(temp_xyz_filename):
            os.remove(temp_xyz_filename)

    # Special cases: Normalize hydrogen molecule representations
    if smiles in ('[HH]', '[H2]', 'HH', '[H].[H]'):
        smiles = '[HH]'

    return smiles




#### cactus_smiles2xyz function ####
def cactus_smiles2xyz(smiles):
    tsmiles = smiles.replace("#","")
    tsmiles = tsmiles.replace("$","")
    result = geturlresult("http://cactus.nci.nih.gov/chemical/structure/%s/file?format=xyz&get3d=True" % tsmiles)
    return result

##### smiles2xyz function ####
#def smiles2xyz(smiles,xyzfile):
#   eoln = "\n"
#   smilefile = wrkdir + "/"+tmpsmi1
#   ofile = open(smilefile,'w')
#   ofile.write(smiles); ofile.write(eoln)
#   ofile.close()
#   cmd6 = babel + " --ffuff --gen3d -ismi " + smilefile + " -oxyz " + xyzfile + " >& " + wrkdir + "/junk.err"
#   os.system(cmd6)
#
#   #### if nan's are produced then use cactus smiles2xyz rest interface ####
#   with open(xyzfile,'r') as ff:
#      test = ff.read()
#   if "nan" in test:
#      xyzdata = cactus_smiles2xyz(smiles)
#      with open(xyzfile,'w') as ff:
#         ff.write(xyzdata)

#### smiles2xyz function ####
def smiles2xyz(smiles,xyzfile):
   cmd6 = esmiles2xyz + ' "' + smiles.strip() + '" ' +xyzfile
   print("cmd6=",cmd6)
   #os.system(cmd6)
   result = subprocess.check_output(cmd6,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
   print("xyzfile=")

   #### if nan's are produced then use cactus smiles2xyz rest interface ####
   with open(xyzfile,'r') as ff:
      test = ff.read()
   if 'nan' in test:
      xyzdata = cactus_smiles2xyz(smiles)
      with open(xyzfile,'w') as ff:
         ff.write(xyzdata+eoln)




#### xyz2InChI function ####
def xyz2InChI(xyz_data):
    """
    Converts XYZ data (as a string) to InChI using Open Babel.

    Args:
        xyz_data (str): A multi-line string containing XYZ format data.

    Returns:
        str: InChI string or empty string on failure.
    """
    inchi = ''
    
    try:
        # Open Babel command to convert XYZ to InChI using stdin
        cmd = "obabel -ixyz - -oinchi"
        
        # Run Open Babel with the XYZ data passed via stdin
        result = subprocess.run(cmd, input=xyz_data.encode(), shell=True, capture_output=True, text=True)
        
        # Extract the InChI string if successful
        if result.stdout:
            inchi = result.stdout.strip().split()[0]  # Get only the InChI string
    except Exception as e:
        print(f"Error converting XYZ to InChI: {e}")
        inchi = ''

    return inchi



#### xyz2InChIKey function ####
def xyz2InChIKey(xyz_data):
    """
    Converts XYZ data (as a string) to an InChIKey using Open Babel.

    Args:
        xyz_data (str): A multi-line string containing XYZ format data.

    Returns:
        str: InChIKey string or an empty string on failure.
    """
    temp_xyz_filename = None  # Define before use
    inchi_key = ''

    try:
        # Write XYZ data to a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".xyz") as temp_xyz:
            temp_xyz.write(xyz_data.encode())
            temp_xyz_filename = temp_xyz.name  # Store filename

        # Open Babel command to convert XYZ file to InChIKey
        cmd = f"obabel -ixyz {temp_xyz_filename} -oinchikey"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

        # Extract InChIKey string if successful
        if result.stdout:
            inchi_key = result.stdout.strip().split()[0]  # Get only the InChIKey

    except Exception as e:
        print(f"Error converting XYZ to InChIKey: {e}")
        inchi_key = ''

    finally:
        # Ensure temp file is cleaned up
        if temp_xyz_filename and os.path.exists(temp_xyz_filename):
            os.remove(temp_xyz_filename)

    return inchi_key


#### smiles2InChI function ####
def smiles2InChI(smiles):
   eoln = "\n"
   inchi = ''
   try:
      smilefile = wrkdir + "/"+tmpsmi1
      inchifile = wrkdir + "/"+tmpsmi2
      ofile = open(smilefile,'w')
      ofile.write(smiles); ofile.write(eoln)
      ofile.close()
      cmd6 = obabel + " -ismi " + smilefile + " -oinchi -O" + inchifile 
      result = subprocess.check_output(cmd6,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
      sdat = []
      ofile = open(inchifile,'r')
      for line in ofile:
         sdat.append(line)
      ofile.close()
      inchi = sdat[0].split()[0]
   except:
      inchi = ''
   return inchi


#### smiles2InChIKey function ####
def smiles2InChIKey(smiles):
   eoln = "\n"
   inchi = ''
   try:
      smilefile = wrkdir + "/"+tmpsmi1
      inchifile = wrkdir + "/"+tmpsmi2
      ofile = open(smilefile,'w')
      ofile.write(smiles); ofile.write(eoln)
      ofile.close()
      cmd6 = obabel + " -ismi " + smilefile + " -oinchikey -O" + inchifile 
      result = subprocess.check_output(cmd6,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
      sdat = []
      ofile = open(inchifile,'r')
      for line in ofile:
         sdat.append(line)
      ofile.close()
      inchi = sdat[0].split()[0]
   except:
      inchi = ''
   return inchi

def removespace_basis(basis):
   if ('ry' not in basis.lower()) and ('hartree' not in basis.lower()):
      basis = basis.replace(" ", "")
   return basis


periodic_table_charge = {
    'H'  : 1,
    'He' : 2,
    'Li' : 3,
    'Be' : 4,
    'B'  : 5,
    'C'  : 6,
    'N'  : 7,
    'O'  : 8,
    'F'  : 9,
    'Ne' : 10,
    'Na' : 11,
    'Mg' : 12,
    'Al' : 13,
    'Si' : 14,
    'P'  : 15,
    'S'  : 16,
    'Cl' : 17,
    'Ar' : 18,
    'K'  : 19,
    'Ca' : 20,
    'Sc' : 21,
    'Ti' : 22,
    'V'  : 23,
    'Cr' : 24,
    'Mn' : 25,
    'Fe' : 26,
    'Co' : 27,
    'Ni' : 28,
    'Cu' : 29,
    'Zn' : 30,
    'Ga' : 31,
    'Ge' : 32,
    'As' : 33,
    'Se' : 34,
    'Br' : 35,
    'Kr' : 36,
    'Rb' : 37,
    'Sr' : 38,
    'Y'  : 39,
    'Zr' : 40,
    'Nb' : 41,
    'Mo' : 42,
    'Tc' : 43,
    'Ru' : 44,
    'Rh' : 45,
    'Pd' : 46,
    'Ag' : 47,
    'Cd' : 48,
    'In' : 49,
    'Sn' : 50,
    'Sb' : 51,
    'Te' : 52,
    'I'  : 53,
    'Xe' : 54,
    'Cs' : 55,
    'Ba' : 56,
    'La' : 57,
    'Ce' : 58,
    'Pr' : 59,
    'Nd' : 60,
    'Pm' : 61,
    'Sm' : 62,
    'Eu' : 63,
    'Gd' : 64,
    'Tb' : 65,
    'Dy' : 66,
    'Ho' : 67,
    'Er' : 68,
    'Tm' : 69,
    'Yb' : 70,
    'Lu' : 71,
    'Hf' : 72,
    'Ta' : 73,
    'W'  : 74,
    'Re' : 75,
    'Os' : 76,
    'Ir' : 77,
    'Pt' : 78,
    'Au' : 79,
    'Hg' : 80,
    'Tl' : 81,
    'Pb' : 82,
    'Bi' : 83,
    'Po' : 84,
    'At' : 85,
    'Rn' : 86,
    'Fr' : 87,
    'Ra' : 88,
    'Ac' : 89,
    'Th' : 90,
    'Pa' : 91,
    'U'  : 92,
    'Np' : 93,
    'Pu' : 94,
    'Am' : 95,
    'Cm' : 96,
    'Bk' : 97,
    'Cf' : 98,
    'Es' : 99,
    'Fm' : 100,
    'Md' : 101,
    'No' : 102,
    'Lr' : 103,
    'Rf' : 104,
    'Ha' : 105,
    'Sg' : 106,
    'Bh' : 107,
    'Hs' : 108,
    'Mt' : 109
}


def mformula_foundHZ(mformula):
   foundHZ = False
   for aa in re.findall(r'[^\d ]+', mformula):
     if (periodic_table_charge[aa]>=21):
        foundHZ = True

   return foundHZ



def smiles2charge(smiles):
  charge = 0
  ss = smiles.split('[')
  if (len(ss)>1):
     ss = ss[1:]
  else:
     ss = []
  for s in ss:
     inside = s.split(']')[0]
     if   (inside.find("+10")!=-1): charge += 10
     elif (inside.find("-10")!=-1): charge -= 10
     elif (inside.find("+9")!=-1): charge += 9
     elif (inside.find("-9")!=-1): charge -= 9
     elif (inside.find("+8")!=-1): charge += 8
     elif (inside.find("-8")!=-1): charge -= 8
     elif (inside.find("+7")!=-1): charge += 7
     elif (inside.find("-7")!=-1): charge -= 7
     elif (inside.find("+6")!=-1): charge += 6
     elif (inside.find("-6")!=-1): charge -= 6
     elif (inside.find("+5")!=-1): charge += 5
     elif (inside.find("-5")!=-1): charge -= 5
     elif (inside.find("+4")!=-1): charge += 4
     elif (inside.find("-4")!=-1): charge -= 4
     elif (inside.find("+3")!=-1): charge += 3
     elif (inside.find("-3")!=-1): charge -= 3
     elif (inside.find("+2")!=-1): charge += 2
     elif (inside.find("-2")!=-1): charge -= 2
     elif (inside.find("+1")!=-1): charge += 1
     elif (inside.find("-1")!=-1): charge -= 1
     elif (inside.find("+")!=-1):  charge += inside.count('+')
     elif (inside.find("-")!=-1):  charge -= inside.count('-')

  return charge


def esmiles2mult_set(smiles,charge,esmiles):
   mult = smiles2mult(smiles,charge)
   if 'mult{' in esmiles:
      isodd = ((mult%2)==1)
      mult0 = evalnum(esmiles.split('mult{')[1].split('}')[0].strip())
      isodd0 = ((mult0%2)==1)
      if (isodd==isodd0):
         mult = mult0
      elif (mult0<2) and isodd:
         mult = 1
      elif (mult0<3) and (not isodd):
         mult = 2
      else:
         mult = mult0-1
   return mult

def smiles2mult(smiles,q):
  mult = 1
  smiles2xyz(smiles,wrkdir + "/"+tmpxyz1)
  pcharge = q
  count = 0
  xyzfile = open(wrkdir + "/"+tmpxyz1,'r')
  for line in xyzfile:
     count += 1
     if (count>2):
        Symb = line.strip().split()[0]
        if Symb in periodic_table_charge:
           pcharge += periodic_table_charge[Symb]
  xyzfile.close()

  if ((pcharge%2)==1):
     mult = 2
  else:
     mult = 1

  return mult


def xyz2mult(xyzfilename,q):
  mult = 1
  pcharge = q
  count = 0
  xyzfile = open(xyzfilename,'r')
  for line in xyzfile:
     count += 1
     if (count>2):
        Symb = line.split()[0]
        if Symb in periodic_table_charge:
           pcharge += periodic_table_charge[Symb]
  xyzfile.close()

  if ((pcharge%2)==1):
     mult = 2
  else:
     mult = 1

  return mult






vdw = {
 'H': 1.20,
 'N': 1.55,
 'NA': 2.27,
 'Na': 2.27,
 'CU': 1.40,
 'Cu': 1.40,
 'CL': 1.75,
 'Cl': 1.75,
 'C': 1.70,
 'O': 1.52,
 'I': 1.98,
 'P': 1.80,
 'B': 1.85,
 'BR': 1.85,
 'Br': 1.85,
 'S': 1.80,
 'SE': 1.90,
 'Se': 1.90,
 'F': 1.47,
 'FE': 1.80,
 'Fe': 1.80,
 'K':  2.75,
 'MN': 1.73,
 'Mn': 1.73,
 'MG': 1.73,
 'Mg': 1.73,
 'ZN': 1.39,
 'Zn': 1.39,
 'HG': 1.8,
 'Hg': 1.8,
 'XE': 1.8,
 'AU': 1.8,
 'Au': 1.8,
 'LI': 1.8,
 'Li': 1.8,
 '.': 1.8
}







#### functions ####
def xyz_molecular_formula(xyz_data):
    """
    Computes the molecular formula from XYZ data provided as a string.

    Args:
        xyz_data (str): A multi-line string in XYZ format.

    Returns:
        str: Molecular formula.
    """
    fdict = {}
    lines = xyz_data.strip().split("\n")
    n = int(lines[0])  # Number of atoms
    atom_lines = lines[2:n+2]  # Skip the first two lines (count + comment)

    for line in atom_lines:
        key = line.split()[0]  # Extract atomic symbol (first column)
        if key in fdict:
            fdict[key] += 1
        else:
            fdict[key] = 1

    # Construct molecular formula
    formula = "".join(f"{key}{value}" for key, value in sorted(fdict.items(), key=operator.itemgetter(0)))

    return formula



def inchionlyHZ(inchi):
   try:
      onlyHZ = True
      for a in re.findall('[A-Z][^A-Z]*', inchi.split("/")[1]):
         aa = re.sub("[^a-zA-Z]","", a)
         if (periodic_table_charge[aa]<21): onlyHZ = False
   except:
      onlyHZ = False

   return onlyHZ

def inchihasHZ(inchi):
   try:
      hasHZ = False
      #for aa in re.findall('[^\d^. ]+',inchi.split("/")[1]):
      for a in re.findall('[A-Z][^A-Z]*', inchi.split("/")[1]):
         aa = re.sub("[^a-zA-Z]","", a)
         if (periodic_table_charge[aa]>=21): hasHZ = True
   except:
      hasHZ = False

   return hasHZ

def parse_job_info_datetime(file_path):
    """
    Parses the job start datetime from the 'Job information' section in an NWChem output file.

    Args:
        file_path (str): Path to the NWChem output file.

    Returns:
        datetime: Parsed job start datetime or None if not found.
    """
    # Regex pattern to match the date line
    date_pattern = re.compile(r"\s*date\s*=\s*(\w{3}\s+\w{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2}\s+\d{4})")

    with open(file_path, 'r') as file:
        for line in file:
            match = date_pattern.search(line)
            if match:
                date_str = match.group(1)
                try:
                    # Parse the matched date string into a datetime object
                    job_datetime = datetime.strptime(date_str, "%a %b %d %H:%M:%S %Y")
                    return job_datetime
                except ValueError:
                    print(f"Failed to parse datetime: {date_str}")
                    return None

    print("No job start datetime found in the file.")
    return None



def parse_detailed_pseudopotentials(file_path):
    """
    Parses detailed pseudopotentials from an NWChem output file.

    Args:
        file_path (str): Path to the NWChem output file.

    Returns:
        dict: Dictionary with element symbols as keys and pseudopotential details as values.
    """
    pseudopotentials = {}
    current_element = None

    with open(file_path, 'r') as file:
        for line in file:
            # Match element and basic properties
            element_match = re.match(r"\s*\d+:\s*([A-Za-z]{1,2})\s+valence charge:\s+([-0-9.]+)\s+lmax=\s+(\d+)", line)
            if element_match:
                current_element = element_match.group(1)
                pseudopotentials[current_element] = {
                    "valence_charge": float(element_match.group(2)),
                    "lmax": int(element_match.group(3)),
                    "comment": "",
                    "pseudopotential_type": None,
                    "highest_angular_component": None,
                    "local_potential_used": None,
                    "non_local_projections": None,
                    "semicore_corrections": None,
                    "cutoff": []
                }
                continue

            # Match comment line
            comment_match = re.match(r"\s*comment\s*:\s*(.*)", line)
            if comment_match and current_element:
                pseudopotentials[current_element]["comment"] = comment_match.group(1).strip()
                continue

            # Match pseudopotential type
            psp_type_match = re.match(r"\s*pseudpotential type\s*:\s*(\d+)", line)
            if psp_type_match and current_element:
                pseudopotentials[current_element]["pseudopotential_type"] = int(psp_type_match.group(1))
                continue

            # Match highest angular component
            angular_match = re.match(r"\s*highest angular component\s*:\s*(\d+)", line)
            if angular_match and current_element:
                pseudopotentials[current_element]["highest_angular_component"] = int(angular_match.group(1))
                continue

            # Match local potential used
            local_pot_match = re.match(r"\s*local potential used\s*:\s*(\d+)", line)
            if local_pot_match and current_element:
                pseudopotentials[current_element]["local_potential_used"] = int(local_pot_match.group(1))
                continue

            # Match number of non-local projections
            nonlocal_proj_match = re.match(r"\s*number of non-local projections:\s*(\d+)", line)
            if nonlocal_proj_match and current_element:
                pseudopotentials[current_element]["non_local_projections"] = int(nonlocal_proj_match.group(1))
                continue

            # Match semicore corrections
            semicore_match = re.match(r"\s*semicore corrections included\s*:\s*([-0-9.]+)\s*\(radius\)\s*([-0-9.]+)\s*\(charge\)", line)
            if semicore_match and current_element:
                pseudopotentials[current_element]["semicore_corrections"] = {
                    "radius": float(semicore_match.group(1)),
                    "charge": float(semicore_match.group(2))
                }
                continue

            # Match cutoff values
            cutoff_match = re.match(r"\s*cutoff\s*=\s*([-0-9.]+)\s+([-0-9.]+)\s*([-0-9.]*)", line)
            if cutoff_match and current_element:
                cutoff_values = [float(val) for val in cutoff_match.groups() if val]
                pseudopotentials[current_element]["cutoff"] = cutoff_values
                continue

    return pseudopotentials



def parse_space_group(file_path):
    """
    Parses space group information from an NWChem output file.
    Defaults to 'P1' if no space group is found.

    Args:
        file_path (str): Path to the NWChem output file.

    Returns:
        dict: A dictionary containing space group information (name and number).
    """
    # Default to P1 (space group number 1)
    space_group_data = {
        "space_group_name": "P1",
        "space_group_number": 1
    }

    # Regular expressions to match space group details
    space_group_name_pattern = re.compile(r"\s*Space\s+Group\s*:\s*([A-Za-z0-9\-/]+)")
    space_group_number_pattern = re.compile(r"\s*Space\s+Group\s+Number\s*:\s*(\d+)")

    with open(file_path, 'r') as file:
        for line in file:
            # Match space group name
            name_match = space_group_name_pattern.search(line)
            if name_match:
                space_group_data["space_group_name"] = name_match.group(1)

            # Match space group number
            number_match = space_group_number_pattern.search(line)
            if number_match:
                space_group_data["space_group_number"] = int(number_match.group(1))

    return space_group_data


def parse_lattice_parameters(unitcell):
    """
    Parses lattice parameters from a unit cell dictionary.

    Args:
        unitcell (dict): Dictionary containing unit cell parameters.

    Returns:
        dict: Parsed lattice parameters including lengths, angles, and lattice vectors.
    """
    lattice_parameters = {
        "a": unitcell.get("a", 0.0),
        "b": unitcell.get("b", 0.0),
        "c": unitcell.get("c", 0.0),
        "alpha": unitcell.get("alpha", 90.0),
        "beta": unitcell.get("beta", 90.0),
        "gamma": unitcell.get("gamma", 90.0),
        "lattice_vectors": unitcell.get("lattice_vectors", [])
    }

    return lattice_parameters


def parse_lattice_type(unitcell, tol=1e-3):
    """
    Determines the lattice type based on unit cell parameters.

    Args:
        unitcell (dict): Dictionary containing unit cell parameters.
        tol (float): Tolerance for floating-point comparisons.

    Returns:
        str: Lattice type (e.g., Cubic, Tetragonal, Hexagonal, etc.)
    """
    # Extract parameters
    a = unitcell.get("a", 0.0)
    b = unitcell.get("b", 0.0)
    c = unitcell.get("c", 0.0)
    alpha = unitcell.get("alpha", 90.0)
    beta = unitcell.get("beta", 90.0)
    gamma = unitcell.get("gamma", 90.0)

    # Helper function for float comparisons
    def is_close(x, y):
        return abs(x - y) < tol

    # Lattice type identification
    if is_close(a, b) and is_close(b, c):
        if is_close(alpha, 90) and is_close(beta, 90) and is_close(gamma, 90):
            return "Cubic"
        elif is_close(alpha, beta) and is_close(beta, gamma) and not is_close(alpha, 90):
            return "Rhombohedral (Trigonal)"
    elif is_close(a, b) and not is_close(c, a):
        if is_close(alpha, 90) and is_close(beta, 90) and is_close(gamma, 90):
            return "Tetragonal"
        elif is_close(alpha, 90) and is_close(beta, 90) and is_close(gamma, 120):
            return "Hexagonal"
    elif not is_close(a, b) and not is_close(b, c):
        if is_close(alpha, 90) and is_close(beta, 90) and is_close(gamma, 90):
            return "Orthorhombic"
        elif is_close(alpha, 90) and not is_close(beta, 90) and is_close(gamma, 90):
            return "Monoclinic"
        else:
            return "Triclinic"

    return "Unknown"


def parse_total_pspw_energy(file_path):
    """
    Parses the Total PSPW energy from an NWChem output file.

    Args:
        file_path (str): Path to the NWChem output file.

    Returns:
        float: Total PSPW energy if found, else None.
    """
    energy_pattern = re.compile(r"Total PSPW energy\s*:\s*([-+]?\d*\.\d+|\d+)[eEdD]?([-+]?\d+)?")

    with open(file_path, 'r') as file:
        for line in file:
            match = energy_pattern.search(line)
            if match:
                base = float(match.group(1))
                exponent = int(match.group(2)) if match.group(2) else 0
                total_energy = base * (10 ** exponent)
                return total_energy

    # Return None if the pattern is not found
    return None





def parse_unitcell_calculation(filename):
   with open(filename,'r') as ff:
      aa = ff.read()

   cell = []
   cell.append("1.0 0.0 0.0")
   cell.append("0.0 1.0 0.0")
   cell.append("0.0 0.0 1.0")
   cell.append("1.0 1.0 1.0")
   cell.append("90.0 90.0 90.0")
   for ll in aa.split("\n"):
      if 'a1=<' in ll: cell[0] = ll
      if 'a2=<' in ll: cell[1] = ll
      if 'a3=<' in ll: cell[2] = ll
      if ('a=' in ll) and ('b=' in ll) and ('c' in ll): cell[3] = ll
      if ('alpha=' in ll) and ('beta=' in ll) and ('gamma' in ll): cell[4] = ll

   return '\n'.join(cell)



def parse_unitcell_from_string(unitcell_string):
    """
    Parses unit cell information from a string into a dictionary.
    """
    # Regex for lattice constants
    constants_pattern = re.search(r'a=\s*([\d\.]+)\s*b=\s*([\d\.]+)\s*c=\s*([\d\.]+)', unitcell_string)
    angles_pattern = re.search(r'alpha=\s*([\d\.]+)\s*beta=\s*([\d\.]+)\s*gamma=\s*([\d\.]+)', unitcell_string)
    
    # Regex for lattice vectors (allow flexible spaces and signs)
    lattice_vectors = []
    for i in range(1, 4):
        vector_pattern = re.search(r'a{}\s*=<\s*([-\d\.]+)\s+([-\d\.]+)\s+([-\d\.]+)\s*>'.format(i), unitcell_string)
        if vector_pattern:
            lattice_vectors.append([float(coord) for coord in vector_pattern.groups()])
        else:
            raise ValueError(f" Error: Could not parse lattice vector a{i}. Line: {unitcell_string}")

    if not constants_pattern or not angles_pattern:
        raise ValueError(" Error: Lattice constants or angles not found.")

    a, b, c = map(float, constants_pattern.groups())
    alpha, beta, gamma = map(float, angles_pattern.groups())

    return {
        'a': a, 'b': b, 'c': c,
        'alpha': alpha, 'beta': beta, 'gamma': gamma,
        'lattice_vectors': lattice_vectors
    }

def convert_unitcell_to_angstrom(unitcell):
    """
    Converts unit cell dimensions and lattice vectors from Bohrs to ngstrms.

    Args:
        unitcell (dict): Unit cell dictionary with keys 'a', 'b', 'c', 'alpha', 'beta', 'gamma', and 'lattice_vectors'.

    Returns:
        dict: Converted unit cell in ngstrms.
    """
    bohr_to_angstrom = 0.529177

    # Convert lattice constants
    converted_cell = {
        'a': unitcell['a'] * bohr_to_angstrom,
        'b': unitcell['b'] * bohr_to_angstrom,
        'c': unitcell['c'] * bohr_to_angstrom,
        'alpha': unitcell['alpha'],
        'beta': unitcell['beta'],
        'gamma': unitcell['gamma'],
        'lattice_vectors': []
    }

    # Convert lattice vectors
    for vector in unitcell['lattice_vectors']:
        converted_vector = [coord * bohr_to_angstrom for coord in vector]
        converted_cell['lattice_vectors'].append(converted_vector)

    return converted_cell




def parse_basis(HZ,outfile):
   basis = 'unknown'
   if (os.path.exists(outfile)):
      started  = False
      finished = False
      count    = 0
      ofile = open(outfile,'r')
      for line in ofile:

         if (line.find('#')==-1) and (line.find("wavefnc cutoff=") != -1):
            if (not HZ): basis = "%.1f Ry" % (evalnum(line.split()[2])*2)
            finished = True

         if (not finished):
            if (started):
               count += 1
               if (line.strip()==''):
                  finished = True
                  for ll in basisl:
                     aa = ll.split()[0].strip()
                     if (aa=='*'):
                        if (not HZ): basis = ll.split()[1]
                     else:
                        if ((not HZ) and (periodic_table_charge[aa]<21)):
                           basis = ll.split()[1]
                        if HZ and (periodic_table_charge[aa]>=21):
                           basis = ll.split()[1]
               elif (count>=2):
                  basisl.append(line)
            else:
               if (line.find('#')==-1) and (line.find("Tag                 Description            Shells   Functions and Types") != -1):
                  started = True
                  count = 0
                  basisl = []
      ofile.close()
      if basis=="crenbl": basis="crenbl_ecp"
      if basis=="stuttgart": basis="stuttgart_rsc_1997"
   return basis



def parse_analytic_hessian(outfile):
   hessian = 'FD'
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("NWChem Analytic Hessian") != -1): hessian = 'Analytic'
      ofile.close()
   return hessian


def parse_program(outfile):
   program = 'unknown'
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("Northwest Computational Chemistry Package (NWChem)") != -1): program = "NWChem " + line.split()[5]
         if (line.find("MOPAC:  VERSION  7.01") != -1): program = "MOPAC:  VERSION  7.01"
      ofile.close()
   return program

def parse_machine(outfile):
   machine = 'unknown'
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ff:
         aa = ff.read()
      if ("MYMACHINENAME:" in aa) and (":MYMACHINENAME" in aa):
         machine = aa.split("MYMACHINENAME:")[1].split(":MYMACHINENAME")[0].strip()
      else:
         for line in aa.split('\n'):
            if ((line.find("hostname        =") != -1)): machine = line.split()[2]
   return machine

def parse_ncpu(outfile):
   ncpu = -1
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile: 
         if ((line.find("nproc           =") != -1)): ncpu = evalnum(line.split()[2])
      ofile.close()
   return ncpu

def parse_wall_time(outfile):
   wall = -1.0
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile: 
         if ((line.find("Total times  cpu:") != -1)):
            ss = line.split()[5].replace('s','')
            wall = evalnum(ss)
      ofile.close()
   return wall

def parse_cputime_step(outfile):
   cputime = -1.0
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("cputime/step:") != -1)):
            ss = line.split()[1]
            cputime = evalnum(ss)
      ofile.close()
   return cputime

def parse_simulation_steps(outfile):
   counts   = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[3])
            counts.append(c)
         if ((line.find("== Energy Calculation ==") != -1)):       clast = counts.pop()
         if ((line.find("CPMD property analysis is off.") != -1)): clast = counts.pop()
      ofile.close()

   n = 0
   for i in range(len(counts)):
      n += counts[i]

   return n

def parse_equilibration_steps(outfile):
   counts   = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[3])
            counts.append(c)
         if ((line.find("== Energy Calculation ==") != -1)):       clast = counts.pop()
         if ((line.find("CPMD property analysis is on.") != -1)): clast = counts.pop()
      ofile.close()

   n = 0
   for i in range(len(counts)):
      n += counts[i]

   return n


def parse_simulation_time(outfile):
   counts   = []
   timesteps = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[3])
            counts.append(c)
         if ((line.find("time step=") != -1)):
            t = eval(line.split()[2])
            timesteps.append(t)
         if ((line.find("== Energy Calculation ==") != -1)):
            clast = counts.pop()
            tlast = timesteps.pop()
         if ((line.find("CPMD property analysis is off.") != -1)):
            clast = counts.pop()
            tlast = timesteps.pop()
      ofile.close()

   simulation_time = 0.0
   for i in range(len(counts)):
      simulation_time += counts[i]*timesteps[i]
   simulation_time = simulation_time*2.41889e-17/1.0e-12

   return simulation_time



def parse_equilibration_time(outfile):
   counts   = []
   timesteps = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[3])
            counts.append(c)
         if ((line.find("time step=") != -1)):
            t = eval(line.split()[2])
            timesteps.append(t)
         if ((line.find("== Energy Calculation ==") != -1)):
            clast = counts.pop()
            tlast = timesteps.pop()
         if ((line.find("CPMD property analysis is on.") != -1)):
            clast = counts.pop()
            tlast = timesteps.pop()
      ofile.close()

   equilibration_time = 0.0
   for i in range(len(counts)):
      equilibration_time += counts[i]*timesteps[i]
   equilibration_time = equilibration_time*2.41889e-17/1.0e-12

   return equilibration_time


def parse_aimdmm_solvent(outfile):
   nsolvent  = 0
   frag_size = 0
   solvation_type = ''
   solvent_type   = ''
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ((line.find("QM/MM Potential Parameters:") != -1)):
               nsolvent = 0
            if ((line.find("fragments kind                =") != -1)):
               nsolvent += line.split().count('1')
            if ((line.find("- shake =    1   1.890   2   3.086   3   1.890") != -1)):
               solvent_type = 'spcwater'
            if ((line.find("- fragment size =") != -1)):
               frag_size = eval(line.split()[4])

   solvent_size = nsolvent*frag_size
   if (nsolvent>0): 
      solvation_type = 'aimdmm'
      molarity       = nsolvent/55.556
    
   return (solvation_type,solvent_type,nsolvent,solvent_size,molarity)

def parse_unitcell(outfile):
   unitcell = {}
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ((line.find("volume :") != -1)): unitcell['omega'] = eval(line.split()[2])
            if ((line.find("a1=<") != -1)): 
               unitcell['a1x'] = eval(line.split()[2])
               unitcell['a1y'] = eval(line.split()[3])
               unitcell['a1z'] = eval(line.split()[4])
            if ((line.find("a2=<") != -1)): 
               unitcell['a2x'] = eval(line.split()[1])
               unitcell['a2y'] = eval(line.split()[2])
               unitcell['a2z'] = eval(line.split()[3])
            if ((line.find("a3=<") != -1)): 
               unitcell['a3x'] = eval(line.split()[1])
               unitcell['a3y'] = eval(line.split()[2])
               unitcell['a3z'] = eval(line.split()[3])
      if ((abs(unitcell['a1y'])<1.e-6) and
          (abs(unitcell['a1z'])<1.e-6) and
          (abs(unitcell['a2x'])<1.e-6) and
          (abs(unitcell['a2z'])<1.e-6) and
          (abs(unitcell['a3x'])<1.e-6) and
          (abs(unitcell['a3y'])<1.e-6) and 
          (abs(unitcell['a1x']-unitcell['a2y'])<1.e-6) and 
          (abs(unitcell['a1x']-unitcell['a3z'])<1.e-6) and 
          (abs(unitcell['a2y']-unitcell['a3z'])<1.e-6)):
         unitcell['unitcell'] = "SC"
         unitcell['unitcell_L'] = unitcell['a1x']

   return unitcell


def parse_aimd_temperatures(outfile):
   temperatures = {}
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ((line.find("Initializing ion velocities:") != -1)):
               temperatures['seed'] = eval(line.split()[8])
               temperatures['initial_temperature'] = eval(line.split()[5].rstrip('K,'))
            if ((line.find("link =   1 Te =") != -1)):
               temperatures['temperature_elc'] = eval(line.split()[5])
            if ((line.find("link =   1 Tr =") != -1)):
               temperatures['temperature_ion'] = eval(line.split()[5])

   return temperatures



def parse_reactionconstraints(outfile):
   constraint_type = ''
   constraint_string = ''
   constraint_indexes = ''
   constraint_value  = ''
   constraint_value1 = ''
   constraint_spring = ''
   bondingson = False
   bondings   = ''
   with open(outfile,'r') as ofile:
      for line in ofile:
         if ((line.find("#Constraint: reaction_type=") != -1)):
            constraint_type = line.split("#Constraint: reaction_type=")[1].split("\n")[0]
         if ((line.find("#Constraint: reaction_indexes=") != -1)):
            constraint_indexes = line.split("#Constraint: reaction_indexes=")[1].split("\n")[0].strip()
         if ((line.find("#Constraint: reaction_gamma=") != -1)):
            constraint_value  = evalnum(line.split("#Constraint: reaction_gamma=")[1].split("\n")[0])
         if ((line.find("#Constraint: reaction_kappa=") != -1)):
            constraint_spring = evalnum(line.split("#Constraint: reaction_kappa=")[1].split("\n")[0])
         if ((line.find("#Constraint: reaction_hash:") != -1)):
            constraint_string += line.split("#Constraint: reaction_hash:")[1].split(":reaction_hash")[0]
         if ((line.find("gamma                        :") != -1)):
            constraint_value1  = evalnum(line.split("gamma                        :")[1].split("\n")[0])
         if (bondingson):
            if (len(line.split())>2):
               bondings += line
            else:
               bondingson = False
         if ((line.find("coefficient index1 index2    :") != -1)):
            bondingson = True
            bondings = ''

   constraints = {}
   constraints['constraint_type']    = constraint_type
   constraints['constraint_string']  = constraint_string
   constraints['constraint_indexes'] = constraint_indexes
   constraints['constraint_value']   = constraint_value
   constraints['constraint_value1']  = constraint_value1
   constraints['constraint_spring']  = constraint_spring
   constraints['bondings']           = bondings

   return constraints




def parse_constraints(xyzfilename,outfile):
   constraint_string = ''
   constraint_value  = 0.0
   constraint_type   = ''
   constraint_index1 = -1
   constraint_index2 = -1
   constraint_index3 = -1
   constraint_index4 = -1
   constraint_mean_force = 0.0
   constraint_mean_force_time = 0.0

   nframes  = 0
   dt       = 0.0
   with open(outfile,'r') as ofile:
      for line in ofile:
         if ((line.find("set nwpw:shake_constraint") != -1)):
            if 'd' in line:
               constraint_type = 'bonddiff'
               constraint_value = eval(line.split()[6].strip('\"'))
               constraint_index1= eval(line.split()[2].strip('\"'))
               constraint_index2= eval(line.split()[4])
               constraint_index3= eval(line.split()[3])
            if 'L' in line:
               constraint_type = 'bond'
               constraint_value = eval(line.split()[5].strip('\"'))*0.529177
               constraint_index1= eval(line.split()[2].strip('\"'))
               constraint_index2= eval(line.split()[3])
         if ((line.find("(shake error=") != -1)):
            if (constraint_type=='bond'):
               constraint_mean_force = eval(line.split()[9])
            if (constraint_type=='bonddiff'):
               constraint_mean_force = eval(line.split()[12])
         if ((line.find("frames used           =") != -1)):
            nframes =  eval(line.split()[3])
         if ((line.find("time interval (au)       :") != -1)):
            dt =  eval(line.split()[4])

   constraint_mean_force_time = nframes*dt

   if constraint_type=='bond':
      constraint_string = xyz_bond_string(xyzfilename,constraint_index1-1,constraint_index2-1)
   if constraint_type=='bonddiff':
      constraint_string = xyz_bonddiff_string(xyzfilename,constraint_index1-1,constraint_index2-1,constraint_index3-1)

   constraints = {}
   constraints['constraint_string']     = constraint_string
   constraints['constraint_value']      = constraint_value
   constraints['constraint_type']       = constraint_type
   constraints['constraint_index1']     = constraint_index1
   constraints['constraint_index2']     = constraint_index2
   constraints['constraint_index3']     = constraint_index3
   constraints['constraint_index4']     = constraint_index4
   constraints['constraint_mean_force'] = constraint_mean_force
   constraints['constraint_mean_force_time'] = constraint_mean_force_time

   return constraints


def parse_aimd_energies(outfile):
   energies  = {}
   energies0 = {}
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ((line.find("Car-Parrinello microcluster calculation") != -1)): energies0 = {}

            if ((line.find("total     energy    :") != -1)):
               energies0['total_energy'] = eval(line.split()[3])

            if ((line.find("total orbital energy:") != -1)):
               energies0['total_orbital_energy'] = eval(line.split()[3])

            if ((line.find("hartree   energy    :") != -1)):
               energies0['hartree_energy'] = eval(line.split()[3])

            if ((line.find("exc-corr  energy    :") != -1)):
               energies0['exc_corr_energy'] = eval(line.split()[3])

            if ((line.find("ion-ion   energy    :") != -1)):
               energies0['ion_ion_energy'] = eval(line.split()[3])

            if ((line.find("Kinetic energy (elc)    :") != -1)):
               energies0['kinetic_energy_elc'] = eval(line.split()[4])

            if ((line.find("Kinetic energy (ion)    :") != -1)):
               energies0['kinetic_energy_ion'] = eval(line.split()[4])

            if ((line.find("LJ energy              :") != -1)):
               energies0['LJ_energy'] = eval(line.split()[3])

            if ((line.find("Residual Coulomb energy:") != -1)):
               energies0['Residual_Coulomb_energy'] = eval(line.split()[3])

            if ((line.find("MM Vibration energy    :") != -1)):
               energies0['MM_Vibration_energy'] = eval(line.split()[4])

            if ((line.find("thermostat energy (elc) :") != -1)):
               energies0['thermostat_energy_elc'] = eval(line.split()[4])

            if ((line.find("thermostat energy (ion) :") != -1)):
               energies0['thermostat_energy_ion'] = eval(line.split()[4])

            if ((line.find("CPMD property analysis is on.") != -1)): energies = energies0
   return energies



def parse_average_potentialenergy(outfile):
   energies = []
   counts   = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("Vaverage  Eaverage :") != -1)):
            e1 = eval(line.split()[3])
            e2 = eval(line.split()[4])
            energies.append((e1,e2))
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[7])
            counts.append(c)
         if ((line.find("== Energy Calculation ==") != -1)):
            clast = counts.pop()
         if ((line.find("CPMD property analysis is off.") != -1)): 
            clast = counts.pop()
            elast = energies.pop()
      ofile.close()

   eave1 = 0.0; eave2 = 0.0; n = 0.0
   for i in range(len(energies)):
      eave1 += counts[i]*energies[i][0]
      eave2 += counts[i]*energies[i][1]
      n    += counts[i]
   eave1 = eave1/(1.0*n)
   eave2 = eave2/(1.0*n)

   return (eave1,eave2)

def parse_variance_potentialenergy(outfile):
   variances = []
   counts    = []
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if ((line.find("Vvariance Evariance:") != -1)):
            v1 = eval(line.split()[2])
            v2 = eval(line.split()[3])
            variances.append((v1,v2))
         if ((line.find("maximum iterations =") != -1)):
            c = eval(line.split()[7])
            counts.append(c)
         if ((line.find("== Energy Calculation ==") != -1)):
            clast = counts.pop()
         if ((line.find("CPMD property analysis is off.") != -1)):
            clast = counts.pop()
            vlast = variances.pop()
      ofile.close()

   vave1 = 0.0; vave2 = 0.0; n = 0.0
   for i in range(len(variances)):
      vave1 += counts[i]*variances[i][0]
      vave2 += counts[i]*variances[i][1]
      n    += counts[i]
   vave1 = vave1/(1.0*n)
   vave2 = vave2/(1.0*n)

   return (vave1,vave2)





def parse_osmiles(outfile):
   osmiles = "nosmiles"
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("osmiles:") != -1): 
            osmiles = line.split("osmiles:")[1].split(":osmiles")[0]
      ofile.close()
   return osmiles


def parse_postsmiles(outfile):
   psmiles = ""
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("psmiles:") != -1): 
            psmiles = line.split("psmiles:")[1].split(":psmiles")[0]
      ofile.close()
   return psmiles


def parse_xc(outfile):
   grid = None
   xc   = None
   notproperty = True
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("VWN V Correlation Functional  1.000 local") != -1):       xc = 'lda'
         if (line.find("PerdewBurkeErnzerhof Exchange Functional  1.000") != -1): xc = 'pbe'
         if (line.find("PBE0 Method XC Functional") != -1):                       xc = 'pbe0'
         if (line.find("Becke 1988 Exchange Functional  1.000") != -1):           xc = 'blyp'
         if (line.find("B3LYP Method XC Potential") != -1):                       xc = 'b3lyp'
         if (line.find("M06-2X Method XC Functional") != -1):                     xc = 'm06-2x'
         if (line.find("LDA (Vosko et al) parameterization") != -1):      xc = 'lda'
         if (line.find("HSE (White and Bird) parameterization") != -1):   xc = 'hse'
         if (line.find("PBE0 (White and Bird) parameterization") != -1):  xc = 'pbe0'
         if (line.find("BLYP (White and Bird) parameterization") != -1):  xc = 'blyp'
         if (line.find("B3LYP (White and Bird) parameterization") != -1): xc = 'b3lyp'
         if (line.find("PBE96 (White and Bird) parameterization") != -1): xc = 'pbe'
         if (notproperty):
            if (grid=='None'):
               if (line.find("Grid used for XC integration:  medium") != -1): grid = '-medium'
               if (line.find("Grid used for XC integration:  coarse") != -1): grid = '-coarse'
               if (line.find("Grid used for XC integration:  fine") != -1):   grid = '-fine'
               if (line.find("Grid used for XC integration:  xfine") != -1):  grid = '-xfine'
         if (line.find("NWChem Property Module") != -1):  notproperty = False
      ofile.close()
      if (xc==None):   xc = 'lda'
      if (grid!=None):
         if (grid!='-medium'):
            xc += grid
   return xc



def parse_charge(outfile):
   charge = 0
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("Charge           :") != -1): charge =  int(evalnum(line.split()[2]))
         if (line.find("total charge:") != -1):      charge =  int(evalnum(line.split()[2]))
      ofile.close()
   return charge


def parse_mult(outfile):
   mult = 1
   if (os.path.exists(outfile)):
      ofile = open(outfile,'r')
      for line in ofile:
         if (line.find("Spin multiplicity:") != -1): mult =  evalnum(line.split()[2])
         if (line.find("open shells     =") != -1):  mult =  evalnum(line.split()[3])+1
         if (line.find("alpha electrons =") != -1):  nup =  evalnum(line.split()[3])
         if (line.find("beta  electrons =") != -1):  
            ndown =  evalnum(line.split()[3])
            mult  = nup-ndown+1
         if ((line.find("(Fourier space)") != -1) and (line.find(" number of electrons: spin up=") != -1)):
            nup   = evalnum(line.split()[5])
            ndown = evalnum(line.split()[11])
            mult = nup-ndown + 1
      ofile.close()
   return mult



def parse_energy(outfile):
   energy = 9.9e9
   if (os.path.exists(outfile)):
      try:
         cmd0 = "fgrep @ " + outfile
         p = os.popen(cmd0)
         s = p.read()
         p.close()
         sp = s.split()
         nn = len(sp)
         if (nn>27):
            energy = evalnum(sp[nn-7])
      except:
         energy = 9.9e9

      ### look CCSD(T) energy or MP2 Energy ###
      with open(outfile,'r') as ff:
         for line in ff:
            if (line.find("CCSD total energy / hartree       =") != -1):    energy =  evalnum(line.split()[6])
            if (line.find("CCSD(T) total energy / hartree       =") != -1): energy =  evalnum(line.split()[6])
            if (line.find("Total MP2 energy") != -1):                       energy =  evalnum(line.split()[3])
            if (line.find("Total CCSD energy:") != -1):                     energy =  evalnum(line.split()[3])
            if (line.find("Total CCSD(T) energy:") != -1):                  energy =  evalnum(line.split()[3])
     
   return energy




def parse_enthalpy(outfile):
   enthalpy = 0.0
   if (os.path.exists(outfile)):
      try:
         cmd2 = "fgrep \"Thermal correction to Enthalpy\" " + outfile
         pfile = os.popen(cmd2)
         for line in pfile:
            if (line.find("Thermal correction to Enthalpy") != -1):   enthalpy  = evalnum(line.split()[8])
         pfile.close()
      except:
         enthalpy = 0.0
   return enthalpy




def parse_entropy(outfile):
   found = False
   entropy = 0.0
   if (os.path.exists(outfile)):
      try:
         cmd3 = "fgrep \"Total Entropy\" " + outfile
         pfile = os.popen(cmd3)
         for line in pfile:
            if ((line.find("Total Entropy") != -1) and (not found)):
               entropy   = evalnum(line.split()[3])
               found = True
         pfile.close()
      except:
         entropy = 0.0
   return entropy


def parse_cosmo_smd(outfile):
   cosmo_smd = 0.0
   foundsmd = False
   if (os.path.exists(outfile)):
      try:
         cmd4 = "fgrep \"1 M fixed-concentration free energy of solvation\" " + outfile
         pfile = os.popen(cmd4)
         for line in pfile:
            if (line.find("1 M fixed-concentration free energy of solvation") != -1):
               cosmo_smd = evalnum(line.split()[10])
               foundsmd = True
         pfile.close()
      except:
         cosmo_smd = 0.0

   if (abs(cosmo_smd)<=1e-8) and foundsmd:
      cosmo_smd = -987654.3210
   return cosmo_smd

def parse_cosmo_smd_solvent(outfile):
   solvent = "water"
   if (os.path.exists(outfile)):
      try:
         cmd4 = "fgrep \"solvname_short:\" " + outfile
         pfile = os.popen(cmd4)
         for line in pfile:
            if (line.find("solvname_short:") != -1):
              solvent = line.split()[1]
         pfile.close()
      except:
         solvent = "water"
   return solvent


def parse_cosmo_smd_e(outfile):
   cosmo_smd_e = 0.0
   if (os.path.exists(outfile)):
      try:
         cmd4 = "fgrep \"total free energy in solvent including G(SMD-CDS)\" " + outfile
         pfile = os.popen(cmd4)
         for line in pfile:
            if (line.find("total free energy in solvent including G(SMD-CDS)") != -1):
               cosmo_smd_e = evalnum(line.split()[8])
         pfile.close()
      except:
         cosmo_smd_e = 0.0
   return cosmo_smd_e


def parse_cosmo(outfile):
   cosmo = 0.0
   foundcosmo = False
   if (os.path.exists(outfile)):
      try:
         cmd4 = "fgrep \"(electrostatic) solvation energy\" " + outfile
         pfile = os.popen(cmd4)
         for line in pfile:
            if (line.find("(electrostatic) solvation energy") != -1):
               cosmo = evalnum(line.split()[6])
               foundcosmo = True
         pfile.close()
         if (cosmo==0.0):
            cmd5 = "fgrep \"skipped: no gas phase energy\" " + outfile
            pfile = os.popen(cmd5)
            for line in pfile:
               if (line.find("skipped: no gas phase energy") != -1):
                  cosmo = -987654321.0
            pfile.close()
      except:
         cosmo = 0.0
   if (abs(cosmo)<=1e-8) and foundcosmo:
      cosmo = -987654.3210
   return cosmo


def parse_cosmo_intrinsic(outfile):
   intrinsic = False
   if (os.path.exists(outfile)):
      try:
         cmd5 = "fgrep \"skipped: no gas phase energy\" " + outfile
         pfile = os.popen(cmd5)
         for line in pfile:
            if (line.find("skipped: no gas phase energy") != -1):
               intrinsic = True
         pfile.close()
      except:
         intrinsic = False
   return intrinsic

def parse_cosmo_dielectric(outfile):
   dielectric = 0.0
   if (os.path.exists(outfile)):
      try:
         cmd4 = "fgrep \"dielectric constant -eps-\" " + outfile
         pfile = os.popen(cmd4)
         for line in pfile:
            if (line.find("dielectric constant -eps-") != -1):
               dielectric = evalnum(line.split()[4])
         pfile.close()
      except:
         dielectric = 0.0
   return dielectric



def parse_spin_penalty(file_path):
    spin_data = {"up": {"penalty_value": 0.0, "indices": []}, "down": {"penalty_value": 0.0, "indices": []}}

    with open(file_path, "r") as file:
        for line in file:
            match = re.match(r"\s*pspspin\s+(up|down)\s+d\s+([-0-9.]+)\s+(.*)", line)
            if match:
                spin_type = match.group(1)  # "up" or "down"
                penalty_value = float(match.group(2))  # Extract penalty value
                indices = list(map(int, match.group(3).split()))  # Convert indices to list of integers
                spin_data[spin_type] = {
                    "penalty_value": penalty_value,
                    "indices": indices
                }

    return spin_data


def apply_spin_penalty(initial_magnetic_moments, spin_penalty):
    """
    Applies spin penalties to the initial magnetic moments.

    Args:
        initial_magnetic_moments (dict): Atom index to initial magnetic moment.
        spin_penalty (dict): Spin penalty with 'up' and 'down' indices.

    Returns:
        dict: Atom index to corrected magnetic moment.
    """

    # Extract up and down penalty indices
    up_indices = set(spin_penalty.get('up', {}).get('indices', []))
    down_indices = set(spin_penalty.get('down', {}).get('indices', []))

    corrected_moments = {}

    for atom_index, moment in initial_magnetic_moments.items():
        if atom_index in up_indices:
            # Up-spin penalized: favor down-spin (negative moment)
            corrected_moments[atom_index] = -abs(moment)
        elif atom_index in down_indices:
            # Down-spin penalized: favor up-spin (positive moment)
            corrected_moments[atom_index] = abs(moment)
        else:
            # No penalty applied
            corrected_moments[atom_index] = moment

    return corrected_moments




def compute_magnetic_moments_nwout(nwout_file):
    """
    Parses an NWChem output file to extract atoms and spin penalties,
    and computes initial magnetic moments using predefined MAGNETIC_ION_SPINS.

    Args:
        nwout_file (str): Path to the NWChem output file.

    Returns:
        dict: Atom index mapped to initial magnetic moment.
    """

    # Predefined magnetic moments for elements
    MAGNETIC_ION_SPINS = {
        # Transition Metals
        'Sc': 0.0, 'Ti': 1.0, 'V': 1.5, 'Cr': 1.5, 'Mn': 2.5, 'Fe': 2.5, 'Co': 1.5, 'Ni': 1.0, 'Cu': 0.5, 'Zn': 0.0,
        'Y': 0.0, 'Zr': 0.5, 'Nb': 1.0, 'Mo': 1.5, 'Tc': 2.0, 'Ru': 1.5, 'Rh': 1.0, 'Pd': 0.0, 'Ag': 0.0, 'Cd': 0.0,
        'Hf': 0.5, 'Ta': 1.0, 'W': 1.5, 'Re': 2.0, 'Os': 1.5, 'Ir': 1.0, 'Pt': 0.0, 'Au': 0.5, 'Hg': 0.0,

        # Lanthanides
        'La': 0.0, 'Ce': 1.0, 'Pr': 1.5, 'Nd': 2.0, 'Pm': 2.5, 'Sm': 2.5, 'Eu': 3.0, 'Gd': 3.5, 'Tb': 3.0,
        'Dy': 2.5, 'Ho': 2.0, 'Er': 1.5, 'Tm': 1.0, 'Yb': 0.5, 'Lu': 0.0,

        # Actinides
        'Th': 0.0, 'Pa': 0.5, 'U': 1.0, 'Np': 1.5, 'Pu': 2.0, 'Am': 2.5, 'Cm': 3.0, 'Bk': 3.5, 'Cf': 4.0,
        'Es': 3.5, 'Fm': 3.0, 'Md': 2.5, 'No': 2.0, 'Lr': 0.5
    }

    atom_list = []
    spin_penalty = {'up': {'penalty_value': 1.0, 'indices': []},
                    'down': {'penalty_value': -1.0, 'indices': []}}
    initial_moments = {}

    # Regex patterns to parse atoms and spin_penalty
    atom_pattern = re.compile(r'^\s*(\d+)\s+([A-Z][a-z]?)\s+.*$')
    spin_penalty_pattern = re.compile(r'spin_penalty\s*=\s*(\{.*?\})', re.DOTALL)

    with open(nwout_file, 'r') as file:
        content = file.read()

        # Step 1: Extract spin_penalty as a JSON-like string
        spin_penalty_match = spin_penalty_pattern.search(content)
        if spin_penalty_match:
            spin_penalty_str = spin_penalty_match.group(1)
            try:
                # Convert string to dictionary
                spin_penalty = json.loads(spin_penalty_str.replace("'", '"'))
            except json.JSONDecodeError:
                print("Error parsing spin_penalty from NWChem output.")

        # Step 2: Parse atom list
        for line in content.splitlines():
            match = atom_pattern.match(line)
            if match:
                atom_index = int(match.group(1))
                element = match.group(2)
                atom_list.append((atom_index, element))

    # Step 3: Extract penalty indices
    up_indices = set(spin_penalty.get('up', {}).get('indices', []))
    down_indices = set(spin_penalty.get('down', {}).get('indices', []))

    # Step 4: Compute magnetic moments
    for index, element in atom_list:
        moment = MAGNETIC_ION_SPINS.get(element, 0.0)  # Default moment

        # Apply spin penalties with corrected logic
        if index in up_indices:
            # If up-spin is penalized, atom prefers down-spin (negative moment)
            initial_moments[index] = -abs(moment)
        elif index in down_indices:
            # If down-spin is penalized, atom prefers up-spin (positive moment)
            initial_moments[index] = abs(moment)
        else:
            # No penalty applied, use default moment
            initial_moments[index] = moment

    return initial_moments




#def parse_xyz_data(file_path):
#    """
#    Parses XYZ coordinates from a given output file.
#
#    Args:
#        file_path (str): Path to the output file.
#
#    Returns:
#        list: A list of tuples containing elements and their XYZ coordinates.
#    """
#    xyz_data = []
#
#    with open(file_path, "r") as file:
#        for line in file:
#            # Match lines that contain atomic elements followed by three coordinates
#            match = re.match(r"^\s*([A-Za-z]+)\s+([-0-9.]+)\s+([-0-9.]+)\s+([-0-9.]+)", line)
#            if match:
#                element = match.group(1)  # Atomic element symbol
#                x, y, z = map(float, match.groups()[1:])  # Convert coordinates to float
#                xyz_data.append((element, x, y, z))
#
#    return xyz_data
#


def parse_output_to_xyz(file_path):
    """
    Parses XYZ coordinates from a formatted output file and returns an XYZ format string.

    Args:
        file_path (str): Path to the output file.

    Returns:
        str: XYZ formatted string.
    """
    xyz_data = []
    parsing_atoms = False
    before_parsing_atoms = False
    counter = 0

    with open(file_path, "r") as file:
        for line in file:
            # Start parsing when the line indicates atomic positions
            if " XYZ format geometry" in line:
                before_parsing_atoms = True
                counter = 0 
                #continue

            if before_parsing_atoms:
               counter += 1
               print("counter=",counter," line=",line)
               if (counter>=5):
                  parsing_atoms = True
                  before_parsing_atoms = False
                  print("parsing_atoms=",parsing_atoms)

        

            # Detect end of atomic coordinate block
            #if parsing_atoms and not re.match(r"\s*\d+\s+[A-Za-z]{1,2}\s+[-0-9.]+\s+[-0-9.]+\s+[-0-9.]+\s+[-0-9.]+", line):
            if parsing_atoms and re.match(r"=========================", line):
                parsing_atoms = False
                print("2parsing_atoms=",parsing_atoms)

            # If parsing, extract the atomic data
            if parsing_atoms:
                #match = re.match(r"\s*(\d+)\s+([A-Za-z]{1,2})\s+[-0-9.]+\s+([-0-9.]+)\s+([-0-9.]+)\s+([-0-9.]+)", line)
                match = re.match(r"\s*([A-Za-z]{1,2})\s+([-0-9.]+)\s+([-0-9.]+)\s+([-0-9.]+)", line)
                if match:
                    element = match.group(1)
                    x, y, z = map(float, match.groups()[1:])
                    xyz_data.append((element, x, y, z))

    # Convert to XYZ format string
    xyz_string = f"{len(xyz_data)}\nXYZ file generated from output\n"
    xyz_string += "\n".join(f"{element} {x:.6f} {y:.6f} {z:.6f}" for element, x, y, z in xyz_data)

    return xyz_string




def parse_xyzblob(outfile,tmpxyzfile):
   xyzblob = ''
   if (os.path.exists(outfile)):
      try:
         count = -1
         xyzdat = []
         ofound = False
         gfound = False
         done = False
         ofile = open(outfile,'r')
         for line in ofile:
           if (not done):
              if (count>0):
                 if (len(line)<=5):
                    #done = True
                    count = -1
                    ofound = False
                    gfound = False
                 else:
                    xyzdat.append(line)
              if (not done):
                 if (count>=0):
                    count += 1
                 if (line.find(" XYZ format geometry") != -1):
                    ofound = True
                 if (line.find("Optimization converged") != -1):
                    ofound = True
                 if (line.find("Failed to converge in maximum number of steps") != -1):
                    ofound = True
                 if (ofound and (line.find("No.") != -1)):
                    gfound = True
                    count = 0
                    xyzdat = []
         ofile.close()

         print("xyzdat=",xyzdat)

         print("Generating xyzfile = ",xyzfile)
         n = len(xyzdat)
         xfile = open(tmpxyzfile,'w')
         xfile.write("%d\n\n" % n)
         for i in range(n):
            split = xyzdat[i].split()
            xfile.write("%s   %f %f %f\n" % (split[1],evalnum(split[3]),evalnum(split[4]),evalnum(split[5])))
         xfile.close()

         n = len(xyzdat)
         xyzblob = "%d\n\n" % n
         for i in range(n):
            split = xyzdat[i].split()
            xyzblob +=  "%s   %f %f %f\n" % (split[1],evalnum(split[3]),evalnum(split[4]),evalnum(split[5]))
      except:
         print("Cannot generate xyzblob ")

   return xyzblob


def nwchem_output_to_cif_string(unitcell_data, xyzblob):
    """
    Generates CIF formatted string from unitcell data and xyz blob.

    Args:
        unitcell_data (dict): Contains lattice constants and lattice vectors.
        xyzblob (str): XYZ data in string format.

    Returns:
        str: CIF formatted data.
    """
    import numpy as np

    # Parse unitcell data
    a = unitcell_data['a']
    b = unitcell_data['b']
    c = unitcell_data['c']
    alpha = unitcell_data['alpha']
    beta = unitcell_data['beta']
    gamma = unitcell_data['gamma']
    lattice_vectors = unitcell_data['lattice_vectors']

    # Parse xyzblob into a structured list
    atom_list = []
    xyz_lines = xyzblob.strip().split('\n')

    try:
        n_atoms = int(xyz_lines[0])  # First line is the number of atoms
    except ValueError:
        raise ValueError(" Error: XYZ blob format is incorrect. First line should be the atom count.")

    # The actual atom data starts from the third line
    for line in xyz_lines[2:2 + n_atoms]:
        parts = line.strip().split()
        if len(parts) < 4:
            continue  # Skip invalid lines
        element = parts[0]
        x, y, z = map(float, parts[1:4])
        atom_list.append({'element': element, 'x': x, 'y': y, 'z': z})

    # Start CIF string construction
    cif_lines = []
    cif_lines.append("data_generated_from_nwchem")
    cif_lines.append("_symmetry_space_group_name_H-M   'P1'")
    cif_lines.append("_symmetry_Int_Tables_number     1")
    cif_lines.append(f"_cell_length_a    {a:.6f}")
    cif_lines.append(f"_cell_length_b    {b:.6f}")
    cif_lines.append(f"_cell_length_c    {c:.6f}")
    cif_lines.append(f"_cell_angle_alpha {alpha:.2f}")
    cif_lines.append(f"_cell_angle_beta  {beta:.2f}")
    cif_lines.append(f"_cell_angle_gamma {gamma:.2f}\n")

    cif_lines.append("loop_")
    cif_lines.append("_atom_site_label")
    cif_lines.append("_atom_site_type_symbol")
    cif_lines.append("_atom_site_fract_x")
    cif_lines.append("_atom_site_fract_y")
    cif_lines.append("_atom_site_fract_z")

    # Convert cartesian coordinates to fractional using lattice vectors
    lattice_matrix = np.array(lattice_vectors).T  # 3x3 matrix with columns as lattice vectors
    inv_lattice = np.linalg.inv(lattice_matrix)

    for idx, atom in enumerate(atom_list, start=1):
        cart_coords = np.array([atom['x'], atom['y'], atom['z']])
        frac_coords = np.dot(inv_lattice, cart_coords)
        element = atom['element']
        cif_lines.append(f"{element}{idx} {element} {frac_coords[0]:.6f} {frac_coords[1]:.6f} {frac_coords[2]:.6f}")

    # Combine all CIF lines into a single string
    cif_content = "\n".join(cif_lines)
    return cif_content






def parse_freqblob(outfile):
   freqblob = ''
   if (os.path.exists(outfile)):
      try:
         freqblob = ''
         ofile = open(outfile,'r')
         started  = False
         finished = False
         for line in ofile:
           if (not finished):
              if (started):
                 if (line.find("Task  times  cpu:") != -1):
                    finished = True
                 else:
                    freqblob += line
              else:
                 if (line.find("P.Frequency") != -1):
                    started  = True
                    freqblob += line
         ofile.close()

         #### add hessian ####
         ofile = open(outfile,'r')
         started  = False
         finished = False
         for line in ofile:
           if (not finished):
              if (started):
                 if ((line.find("center of mass") != -1) or (line.find("HEAT OF FORMATION") != -1)):
                    finished = True
                 else:
                    freqblob += line
              else:
                 if ((line.find("MASS-WEIGHTED PROJECTED HESSIAN (Hartree/Bohr/Bohr/Kamu)") != -1) or (line.find("FORCE MATRIX IN MILLIDYNES/ANGSTROM") != -1)):
                    started  = True
                    freqblob += line
         ofile.close()
      except:
         print("Cannot generate freqblob ")
   return freqblob

#def freqblob_ok(freqblob):
#   freqs = []
#   for line in freqblob.split("\n"):
#      if "P.Frequency" in line:
#         freqs += [ eval(s) for s in line.split()[1:]]
#   if ((min(freqs)<(-1000.0)) and (max(freqs)>5000.0)):
#      ok = False
#   else:
#      ok = True
#   return ok


def parse_calculation_ok(outfile):
   if (os.path.exists(outfile)):
      try:
         ok = True
         cons0 = False
         finalrun = False
         mp2run   = False
         completed = False
         ofile = open(outfile,'r')
         for line in ofile:
            if "Adding bondings spring" in line:
               cons0 = True

            #bad frequencies
            if "P.Frequency" in line:
               freqs = [ evalnum(s) for s in line.split()[1:]]
               if (cons0):
                  if ((min(freqs)<(-75.0)) or (max(freqs)>150000.0)):
                     ok = False
               else:
                  if ((min(freqs)<(-75.0)) or (max(freqs)>5000.0)):
                     ok = False

            #geometry not converged
            if "Failed to converge in maximum" in line: ok = False

            #look for final resubmit
            if "resubmitjob:9" in line: finalrun = True

            #look for MP2 job
            if "Total MP2 energy" in line: mp2run = True

            #dft gradient failed
            if "driver: task_gradient failed" in line: ok = False

            #dft energy not converged
            if "Calculation failed to converge" in line: ok = False

            #check for 3 negative frequencies
            if "Geometry after  100.0% step for mode  3;" in line: ok = False

            if (cons0 and ("Optimization converged" in line)): ok = True

            #look for completion
            if "Total times  cpu:" in line: completed = True
         ofile.close()
         ok = (ok or finalrun or mp2run) and completed
      except:
         ok = False
   else:
      ok = False

   return ok



def parse_number_negative_frequencies(outfile):
   nfreqs = 0
   if (os.path.exists(outfile)):
      try:
         ofile = open(outfile,'r')
         for line in ofile:
            #bad frequencies
            if "P.Frequency" in line:
               freqs = [ evalnum(s) for s in line.split()[1:]]
               for f in freqs:
                  if (f<(-0.5)): nfreqs += 1
         ofile.close()
      except:
         nfreqs = 0
   return nfreqs


def parse_bad_calculation_xyz(outfile):
   vtag       = ""
   xyzdat     = []
   xyzdat2all = []
   xyzdat2mall = []
   usefreqxyz = False
   if (os.path.exists(outfile)):
      try:
         ok = True
         vtag = ""
         mtag = ""
         bad_calculation = False
         completed = False
         usefreqxyz = True
         geomread  = 0
         geomread2 = 0
         geomread2m= 0
         xyzdat     = []
         xyzdat2    = []
         xyzdat2m   = []
         xyzdat2all = []
         xyzdat2mall = []
         freqs_negative = []
         ofile = open(outfile,'r')
         for line in ofile:

            #look for gross failures
            if "There is an error" in line: bad_calculation = True

            #look for machinejob: string
            if "machinejob:" in line:
               ss = line.split()
               for s in ss:
                  if "machinejob:" in s: mtag = s

            #look for resubmitjob: string
            if "resubmitjob:" in line:
               ss = line.split()
               for s in ss:
                  if "resubmitjob:" in s: vtag = s

            #read geometry during optimization
            if (geomread>0): geomread += 1
            if (geomread>2):
               ss = line.split()
               if (len(ss)<3):
                  geomread = 0
               else:
                  xyzdat.append([ss[1],ss[3],ss[4],ss[5]])

            #start read geometry during optimization
            if "No.       Tag          Charge" in line:
               xyzdat = []
               geomread = 1

            #read of 100% bad mode geometry
            if (geomread2>0): geomread2 += 1
            if (geomread2>2):
               ss = line.split()
               if (len(ss)<3):
                  geomread2 = 0
                  xyzdat2all.append(xyzdat2)
               else:
                  xyzdat2.append([ss[1],ss[3],ss[4],ss[5]])

            #start read of 100% bad mode geometry
            if "Geometry after  100.0% step for mode" in line:
               ok = False
               xyzdat2 = []
               geomread2 = 1


            #read of -100% bad mode geometry
            if (geomread2m>0): geomread2m += 1
            if (geomread2m>2):
               ss = line.split()
               if (len(ss)<3):
                  geomread2m = 0
                  xyzdat2mall.append(xyzdat2m)
               else:
                  xyzdat2m.append([ss[1],ss[3],ss[4],ss[5]])

            #start read of -100% bad mode geometry
            if "Geometry after -100.0% step for mode" in line:
               ok = False
               xyzdat2m = []
               geomread2m = 1


            #bad frequencies
            if "P.Frequency" in line:
               freqs = [ evalnum(s) for s in line.split()[1:]]
               if ((min(freqs)<(-1000.0)) or (max(freqs)>5000.0)):
                  ok = False
               for f in freqs:
                  if (f<-0.5): freqs_negative.append(f)

            #geometry not converged
            if "Failed to converge in maximum" in line:
               usefreqxyz = False
               ok = False

            #dft gradient failed
            if "driver: task_gradient failed" in line:
               usefreqxyz = False
               ok = False

            #dft energy not converged
            if "Calculation failed to converge" in line:
               usefreqxyz = False
               ok = False

            #look for completion
            if "Total times  cpu:" in line: completed = True
         ofile.close()
         ok = ok and completed
      except:
         ok = False
   else:
      ok = False

   usefreqxyz = usefreqxyz and (len(xyzdat2all)!=0)
   if (usefreqxyz):
      msg =  "The bad calculation geometry was updated using average of negative frequency modes. " 
      msg += "There are %d negative frequency modes." % len(xyzdat2all)
      msg += "The negative frequencies are: "
      for f in freqs_negative:
         msg += "%.0f cm-1" % f
      msg += "."
      print(msg)
      text2speech(msg)
      #xyzdat = xyzdat2all[0]
      #for j in range(len(xyzdat)):
      #   x  = 0.0
      #   y  = 0.0
      #   z  = 0.0
      #   nx = 0.0
      #   for i in range(len(xyzdat2all)):
      #      x += eval(xyzdat2all[i][j][1])
      #      y += eval(xyzdat2all[i][j][2])
      #      z += eval(xyzdat2all[i][j][3])
      #      nx += 1.0
      #   xyzdat[j][1] = "%f" % (x/nx)
      #   xyzdat[j][2] = "%f" % (y/nx)
      #   xyzdat[j][3] = "%f" % (z/nx)

      x = [0.0]*len(xyzdat)
      y = [0.0]*len(xyzdat)
      z = [0.0]*len(xyzdat)
      nx = 0.0
      for i in range(len(xyzdat2all)):
         nx += 1.0
         if (random.randint(0,1)==1):
            for j in range(len(xyzdat)):
               x[j] += evalnum(xyzdat2all[i][j][1])
               y[j] += evalnum(xyzdat2all[i][j][2])
               z[j] += evalnum(xyzdat2all[i][j][3])
         else:
            for j in range(len(xyzdat)):
               x[j] += evalnum(xyzdat2mall[i][j][1])
               y[j] += evalnum(xyzdat2mall[i][j][2])
               z[j] += evalnum(xyzdat2mall[i][j][3])
      for j in range(len(xyzdat)):
         xyzdat[j][1] = "%f" % (x[j]/nx)
         xyzdat[j][2] = "%f" % (y[j]/nx)
         xyzdat[j][3] = "%f" % (z[j]/nx)
    
   if (xyzdat!=[]):
      xyz = "%d\n\n" % len(xyzdat)
      for ss in xyzdat:
         xyz += "%s  %s %s %s\n" % (ss[0],ss[1],ss[2],ss[3])
      hasxyz = True
   else:
      hasxyz = False
      xyz    = ""

   if (bad_calculation):
      hasxyz = False
      xyz    = ""

   return (hasxyz,xyz,vtag,mtag)


      

def parse_eigblob(outfile):
   eigblob = ''
   if (os.path.exists(outfile)):
      try:
         unrestricted = False
         #cmd5 = "fgrep \"DFT Final Beta Molecular Orbital Analysis\" " + outfile
         cmd5 = "fgrep \"Final Beta Molecular Orbital Analysis\" " + outfile
         pfile = os.popen(cmd5)
         for line in pfile:
            #if (line.find("DFT Final Beta Molecular Orbital Analysis") != -1):
            if (line.find("Final Beta Molecular Orbital Analysis") != -1):
               unrestricted = True
         pfile.close()

         cmd6 = "fgrep \"Vector\"" + outfile
         eigblob = ''
         pspwset = False
         ofile = open(outfile,'r')
         for line in ofile:
            #if (line.find("DFT Final Alpha Molecular Orbital Analysis") != -1):
            if (line.find("Final Alpha Molecular Orbital Analysis") != -1):
               eigblob = 'alpha\n'
            #if (line.find("DFT Final Beta Molecular Orbital Analysis") != -1):
            if (line.find("Final Beta Molecular Orbital Analysis") != -1):
               eigblob += '\nbeta\n'
            #if (line.find("DFT Final Molecular Orbital Analysis") != -1):
            if (line.find("Final Molecular Orbital Analysis") != -1):
               eigblob = 'restricted\n'
            if (line.find("Vector") != -1): eigblob += line

            if (pspwset):
               if (len(line.split())>1):
                  eigblob += line
               else:
                  pspwset = False
            elif (line.find("virtual orbital energies:") != -1):
               eigblob += line
               pspwset  = True
            elif (line.find("orbital energies:") != -1):
               eigblob = line
               pspwset = True

         ofile.close()

      except:
         eigblob = ''
   return eigblob


def parse_matrix_elements(outfile):
   mdict = {}
   mdict['format'] = {'version':"0.1"}
   mdict['generator'] = {'source': 'nwchem'}
   mdict['generator']['version'] = '0.1.2.3'
   mdict['integral_sets'] = [{'metadata': {'molecule_name':'unknown'}}]
   mdict['integral_sets'][0]['basis_set'] = {'name':'unknown', 'type':'gaussian'}
   mdict['integral_sets'][0]['geometry'] = {'units':'angstrom','coordinate_system':'cartesian','symmetry':'c1','atoms':[]}
   mdict['integral_sets'][0]['coulomb_repulsion'] = {'units':'hartree','value':0.0}
   mdict['integral_sets'][0]['scf_energy'] = {'units':'hartree','value':0.0}
   mdict['integral_sets'][0]['scf_energy_offset'] = {'units':'hartree','value':0.0}
   #mdict['integral_sets']['ccsd_energy'] = {'units':'hartree','value':0.0}
   mdict['integral_sets'][0]['energy_offset'] = {'units':'hartree','value':0.0}
   mdict['integral_sets'][0]['fci_energy'] = {'lower':0.0, 'units':'hartree','upper':0.0,'value':0.0}
   mdict['integral_sets'][0]['n_orbitals'] = 0
   mdict['integral_sets'][0]['n_electrons'] = 0
   mdict['integral_sets'][0]['hamiltonian'] = {'one_electron_integrals':{'units':'hartree','format':'sparse','values':[]}, 'two_electron_integrals':{'units':'hartree','format':'sparse','index_convention':'mulliken','values':[]}}

   if (os.path.exists(outfile)):
      try:
         h1set = False
         b1set = False
         b2set = False
         e1set = False
         e1count = 0
         gsenergy = 0.0
         g1set = False
         s0set = False
         s1set = False
         s2set = False
         v2set = False
         ofile = open(outfile,'r')
         for line in ofile:
            if (line.find("Number of active orbitals") != -1):
                mdict['integral_sets'][0]['n_orbitals'] = eval(line.split()[4])
            if (line.find("Number of active alpha electrons") != -1):
                mdict['integral_sets'][0]['n_electrons'] += eval(line.split()[5])
            if (line.find("Number of active beta electrons") != -1):
                mdict['integral_sets'][0]['n_electrons'] += eval(line.split()[5])
            #if (line.find("CCSD total energy / hartree       =") != -1):
            #    gsenergy = eval(line.split()[6])
            #    state = {'state':{'label':'|G>','superposition':[], 'energy':{'units':'hartree','value': gsenergy}}}
            #   mdict['integral_sets']['ccsd_energy']['value'] = eval(line.split()[6])
            if (line.find("EHF(total)         =") != -1):
               mdict['integral_sets'][0]['scf_energy']['value'] = eval(line.split()[2])
            if (line.find("Shift (HFtot-HFA)  =") != -1):
               mdict['integral_sets'][0]['scf_energy_offset']['value'] = eval(line.split()[3])
            if (line.find("Northwest Computational Chemistry Package (NWChem)") != -1):
               mdict['generator']['version'] = line.split()[5]
            if (line.find("enrep_tce =") != -1):
               mdict['integral_sets'][0]['coulomb_repulsion']['value'] = eval(line.split()[2])

            if (line.find("end_two_electron_integrals") != -1):
               v2set = False

            if (v2set):
               ss = line.strip().split()
               mdict['integral_sets'][0]['hamiltonian']['two_electron_integrals']['values'].append([eval(ss[0]),eval(ss[1]),eval(ss[2]),eval(ss[3]),eval(ss[4])])

            if (line.find("end_one_electron_integrals") != -1):   h1set = False;
            if (line.find("begin_two_electron_integrals") != -1): h1set = False; v2set = True

            if (h1set):
               ss = line.split()
               mdict['integral_sets'][0]['hamiltonian']['one_electron_integrals']['values'].append([eval(ss[0]),eval(ss[1]),eval(ss[2])])

            if (line.find("begin_one_electron_integrals") != -1): h1set = True
            if (g1set):
               ss = line.split()
               if (len(ss)<1): 
                  g1set = False
               else:
                  tt = {'name':ss[1], 'coords':[eval(ss[3]),eval(ss[4]),eval(ss[5])]}
                  mdict['integral_sets'][0]['geometry']['atoms'].append(tt)
            if ('#' not in line) and (line.find(" ---- ---------------- ---------- -------------- -------------- --------------") != -1): g1set = True

            if (b1set):
               ss = line.split()
               if (len(ss)<1): 
                  b1set = False
                  b2set = True
               else:
                  tt = {'name':ss[1], 'type': 'gaussian'}
                  mdict['integral_sets'][0]['basis_set'] = tt
                  #mdict['integral_sets']['basis_set'].append(tt)
            if ('#' not in line) and (not b2set) and (line.find(" ---------------- ------------------------------  ------  ---------------------") != -1): b1set = True

            if (e1set):
               ss = line.split()
               if (line.find("Summary of allocated global arrays") != -1): 
                  e1set = False
                  mdict['integral_sets'][0]['initial_state_suggestions'].append(state)
               elif (line.find("Excitation energy / hartree =") != -1): 
                  if (e1count>0):
                     mdict['integral_sets'][0]['initial_state_suggestions'].append(state)
                  e1count += 1
                  chi = "|E%d>" % (e1count-1)
                  state = {'state':{'label':chi,'superposition':[], 'energy':{'units':'hartree','value': gsenergy+eval(ss[5])}}}
               elif (line.find("CCSD total energy / hartree       =") != -1):
                  gsenergy = eval(line.split()[6])
                  state = {'state':{'label':'|G>','superposition':[], 'energy':{'units':'hartree','value': gsenergy}}}
                  e1count += 1
               elif (s0set):
                  if (len(ss)<3):
                     s0set = False
                  else:
                     sss = [eval(ss[0])] + line.replace(":","").split()[1:]
                     state['state']['superposition'].append(sss)
               elif (line.find("Reference string") != -1): 
                  s0set = True
               elif (s1set):
                  if (len(ss)<3):
                     s1set = False
                  else:
                     sss = [eval(ss[0])] + line.replace(":","").split()[1:]
                     state['state']['superposition'].append(sss)
               elif (line.find("Singles strings") != -1): 
                  s1set = True
           
               elif (s2set):
                  if (len(ss)<3):
                     s2set = False
                  else:
                     sss = [eval(ss[0])] + line.replace(":","").split()[1:]
                     state['state']['superposition'].append(sss)
               elif (line.find("Doubles strings") != -1): 
                  s2set = True

            #if (line.find("No. of excited states :") != -1):
            if (line.find("CCSD iterations") != -1):
                  e1set = True
                  mdict['integral_sets'][0]['initial_state_suggestions'] = []

         ofile.close()
         #mblob = yaml.dump(mdict, default_flow_style=False)
         #mblob = yaml.dump(mdict)
      except:
         mdict = {}
   return mdict



def parse_wannier_centers(file_path):
    """
    Parses the final position of Wannier centers from an NWChem output file.
    Groups them by atom number and labels them with atom types.
    
    Args:
        file_path (str): Path to the NWChem output file.

    Returns:
        dict: Dictionary containing atom numbers, atom types, and Wannier orbital counts.
    """
    with open(file_path, 'r') as f:
        lines = f.readlines()
    
    # Find the last occurrence of 'final position of Wannier centers' for spin up and down
    up_start, down_start = None, None
    for i in range(len(lines) - 1, -1, -1):
        if "final position of Wannier centers" in lines[i]:
            if down_start is None:
                down_start = i
            elif up_start is None:
                up_start = i
                break

    if up_start is None or down_start is None:
        #raise ValueError("Could not find 'final position of Wannier centers' for both spins.")
        return

    def extract_wannier_data(start_line):
        """Extracts Wannier data from the given section."""
        wannier_dict = {}
        pattern = re.compile(r"psi\s+\d+\s+\(.*\)\s+-\s+spin\s+(up|down)\s+orbital, nearest ion=\s*([A-Za-z]+)\s+(\d+)")

        for line in lines[start_line:]:
            match = pattern.search(line)
            if match:
                spin = match.group(1)  # "up" or "down"
                atom_type = match.group(2)  # Atomic symbol (e.g., Fe, O, Ru)
                atom_num = int(match.group(3))  # Atom number

                if atom_num not in wannier_dict:
                    wannier_dict[atom_num] = {"type": atom_type, "up": 0, "down": 0}
                
                # Increment spin count
                if spin == "up":
                    wannier_dict[atom_num]["up"] += 1
                else:
                    wannier_dict[atom_num]["down"] += 1

            elif "== Center of Charge ==" in line:
                break  # Stop parsing when reaching the next section

        return wannier_dict

    # Extract Wannier data for spin up and spin down
    up_wannier = extract_wannier_data(up_start)
    down_wannier = extract_wannier_data(down_start)

    # Merge up and down spin data
    combined_wannier = {}
    for atom in set(up_wannier.keys()).union(down_wannier.keys()):
        combined_wannier[atom] = {
            "type": up_wannier.get(atom, {}).get("type", down_wannier.get(atom, {}).get("type", "Unknown")),
            "up": up_wannier.get(atom, {}).get("up", 0),
            "down": down_wannier.get(atom, {}).get("down", 0)
        }

    return combined_wannier



def parse_dly_wannier_centers(file_path):
    with open(file_path, 'r') as f:
        lines = f.readlines()

    dly_data = {}
    inside_dly_block = False

    # Identify start of DLY block
    for line in lines:
        if "Damle-Lin-Ying Algorithm" in line:
            inside_dly_block = True
            continue

        if inside_dly_block:
            # Terminate on reaching the end of DLY section
            if "== Center of Charge ==" in line or "output psi filename" in line:
                break

            # Match DLY orbital data
            match = re.search(r"psi\s+\d+\s+\(.*\)\s+-\s+spin\s+(up|down)\s+orbital, nearest ion=\s*([A-Za-z]+)\s+(\d+)", line)
            if match:
                spin = match.group(1)
                atom_type = match.group(2)
                atom_num = int(match.group(3))

                if atom_num not in dly_data:
                    dly_data[atom_num] = {"type": atom_type, "up": 0, "down": 0}

                if spin == "up":
                    dly_data[atom_num]["up"] += 1
                else:
                    dly_data[atom_num]["down"] += 1

    return dly_data





def compute_wannier_magnetization(wannier_data):
    """
    Computes the Wannier magnetization for each atom.

    Args:
        wannier_data (dict): Dictionary containing atom numbers, atom types, 
                             and counts of spin-up and spin-down Wannier orbitals.

    Returns:
        dict: Dictionary where keys are atom numbers and values contain atom type and magnetization.
    """
    magnetization_data = {}

    for atom_num, data in wannier_data.items():
        spin_up = data["up"]
        spin_down = data["down"]
        atom_type = data["type"]

        # Compute Wannier-based magnetization
        magnetization = spin_up - spin_down

        # Store results
        magnetization_data[atom_num] = {
            "type": atom_type,
            "wannier_magnetization": magnetization
        }

    return magnetization_data




def parse_qsharp_norbs(outfile):
   norbs = 2
   ofile = open(outfile,'r')
   for line in ofile:
      if (line.find("Number of active orbitals") != -1):
         norbs = evalnum(line.split()[4])
   ofile.close()
   return norbs

def parse_qsharp_nalpha(outfile):
   nalpha = 1
   ofile = open(outfile,'r')
   for line in ofile:
      if (line.find("Number of active alpha electrons") != -1):
         nalpha =  evalnum(line.split()[5])
   ofile.close()
   return nalpha

def parse_qsharp_nbeta(outfile):
   nbeta = 1
   ofile = open(outfile,'r')
   for line in ofile:
      if (line.find("Number of active beta electrons") != -1):
         nbeta = evalnum(line.split()[5])
   ofile.close()
   return nbeta

def parse_qsharp_nroots(outfile):
   nroots = 0
   ofile = open(outfile,'r')
   for line in ofile:
      if (line.find("No. of excited states :") != -1):
         nroots = evalnum(line.split()[5])
   ofile.close()
   return nroots


def parse_jobfinished(outfile):
   jobfinished = False
   if (os.path.exists(outfile)):
      try:
         cmd = "fgrep \"maximum total M-bytes\" " + outfile
         pfile = os.popen(cmd)
         for line in pfile:
            if (line.find("maximum total M-bytes")!=-1):
               jobfinished = True
      except:
         jobfinished = False

   return jobfinished


def parse_aimdjob(outfile):
   aimdjob = False
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if (line.find("Car-Parrinello microcluster calculation") != -1): aimdjob = True
   return aimdjob


def parse_homolumojob(outfile):
   homolumojob = False
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ("homolumoresubmitjob:" in line): homolumojob = True
   return homolumojob


def parse_hrotorjob(outfile):
   hrotorjob = False
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ("hrotorresubmitjob:" in line): hrotorjob = True
   return hrotorjob

def parse_hrotorreplacejob(outfile):
   hrotorreplacejob = False
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ("hrotorreplacejob" in line): hrotorreplacejob = True
   return hrotorreplacejob



def parse_tsample_filenames(outfile):
   outfile_directory = outfile[:outfile.rfind('/')+1]
   tsample = ''
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if (line.find("ion_motion_filename") != -1):
               tt = line.split()[1]
               tsample = tt[tt.rfind('/')+1:].split('.')[0]

   tsample_xyz        = outfile_directory + tsample + ".xyz"
   tsample_ion_motion = outfile_directory + tsample + ".ion_motion"
   tsample_emotion    = outfile_directory + tsample + ".emotion"
   tsample_fei        = outfile_directory + tsample + ".fei"
   return (tsample_xyz,tsample_ion_motion,tsample_emotion,tsample_fei)

def parse_gr_filenames(outfile):
   outfile_directory = outfile[:outfile.rfind('/')+1]
   gr_filenames = []
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if (line.find("creating gr filename:") != -1):
               tt = line.split()[2]
               gr_filenames.append(outfile_directory+tt[tt.rfind('/')+1:])
   return gr_filenames


def parse_hist_filenames(outfile):
   outfile_directory = outfile[:outfile.rfind('/')+1]
   hist_filenames = []
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if (line.find("creating hist filename:") != -1):
               tt = line.split()[2]
               hist_filenames.append(outfile_directory+tt[tt.rfind('/')+1:])
   return hist_filenames


def parse_calculation_type_aimd(outfile):
   calctype = ' '
   if (os.path.exists(outfile)):
      with open(outfile,'r') as ofile:
         for line in ofile:
            if ((line.find("NWPW PSPW Calculation") != -1) and 
                (calctype[-1]!='e')):                               calctype += 'e'
            if (line.find("CPMD property analysis is off.") != -1): calctype += 'q'
            if (line.find("CPMD property analysis is on.") != -1):  calctype += 'd'
   return calctype.strip()


#############################################
#                                           #
#             get_frequency                 #
#                                           #
#############################################

# returns the freqency and eigvector for a given frequency number, fnum.

def get_frequency(frequency_blob,fnum):

   all_lines2 = frequency_blob.split("\n")
   pcount_num = (fnum-1)/6
   shift      = (fnum-1)%6
   freqs = []
   freqdat = []
   count  = 0
   pcount = -1
   done = False
   for line in all_lines2:
     if (not done):
        if (pcount==pcount_num):
           count += 1
           if (count>1):
              if (len(line)<=5):
                 done = True
              else:
                 freqdat.append(line)
        if (not done):
           if (line.find("P.Frequency") != -1):
              count = 0
              pcount += 1
              if (pcount==pcount_num):
                 freqs.append(line)

   splt = freqs[0].split()
   w = evalnum(splt[shift+1])

   freq = []
   n = len(freqdat)
   for i in range(n):
      split = freqdat[i].split()
      freq.append(evalnum(split[shift+1]))

   return (w,freq)

#############################################
#                                           #
#             analyze_frequency             #
#                                           #
#############################################
def analyze_frequency(w):
   minfreq = 0.1
   temp = 298.15
   AUKCAL=627.509469
   c=2.998e10
   h=6.626e-27
   kgas=1.3807e-16
   Rgas = 1.98630/1000.00/AUKCAL

   #print("Temperature=%7.2f  freq= %8.3f cm-1" % (temp,w))
   ethermal = 0.0
   Svib = 0.0
   if (w>minfreq):
      thetav = w*(h*c/kgas)
      xdum   = exp(-thetav/temp)
      xdum   = xdum/(1.00-xdum)
      ethermal =  thetav*(0.50 + xdum)*Rgas
      xdum   = thetav/temp
      if (xdum>0.0):
         Svib   =  (xdum/(exp(xdum)-1.00) - log(1.00-exp(-xdum)))*Rgas
      else:
         Svib = 0.0
      #print("  - contribution to thermal correction to enthalpy= %8.3f kcal/mol (%10.6f)" %  (ethermal*AUKCAL,ethermal))
      #print("  - contribution to Entropy                       = %8.3f cal/mol-k"       %  (Svib*AUKCAL*1000.0))

   return (ethermal,Svib)


#############################################
#                                           #
#               w_freq_hrotor               #
#                                           #
#############################################
def w_freq_hrotor(rgroup,tphi,v):

   wall = []
   for kk in rgroup:
      k1 = kk-1
      w  = tphi[3*k1]*v[3*k1] + tphi[3*k1+1]*v[3*k1+1] + tphi[3*k1+2]*v[3*k1+2]
      wall.append(w)
   failed = False
   if (wall[0]<0): 
      for w in wall:
         if (w>0): failed = True
   else:
      for w in wall:
         if (w<0): failed = True

   if failed:
      wmin = 0.0
   else:
      wmin = 9.9e99
      for w in wall:
         if (abs(w) < abs(wmin)): wmin = w

   return wmin



#############################################
#                                           #
#            parse_hrotor_blob              #
#                                           #
#############################################

# returns the freqency and eigvector for a given frequency number, fnum.

def parse_hrotor_blob(filename,xyz_blob,freq_blob):
   #
   eoln = "\n"
   tstr = ""
   
   R          = 1.986
   boltzman   = 1.38e-23
   plank      = 6.63e-34
   CONVERT_SI = 1.67e-47

   hrotorforce = False
   hrotorzero  = False
   odata = ''
   headerdata = ''
   with open(filename,'r') as ofile:
      for line in ofile:
         if ('#@@' in line): headerdata += line
         if ('hrotorforce' in line): hrotorforce = True
         if ('hrotorzero' in line):  hrotorzero  = True
         if ('hrotoroverlapset:' in line) and (':hrotoroverlapset' in line): 
            odata = line.split('hrotoroverlapset:')[1].split(':hrotoroverlapset')[0].strip()
      

   T       = evalnum(headerdata.split("#@@   Temperature =")[1].split("\n")[0])
   nphi    = evalnum(headerdata.split("#@@   nphi     =")[1].split("\n")[0])
   NNmax   = evalnum(headerdata.split("#@@   NNmax    =")[1].split("\n")[0])
   sym_num = evalnum(headerdata.split("#@@   rsym_num =")[1].split("\n")[0])
   Im      = evalnum(headerdata.split("#@@    Im  =")[1].split("(")[0])
   theory  = headerdata.split("#@@ theory =")[1].split("\n")[0].strip()
   drphi = []
   for xxx in headerdata.split("#@@ drion/dphi =")[1:]:
      drphi += [evalnum(f) for f in xxx.split("\n")[0].strip().split()]
   tphi = []
   for xxx in headerdata.split("#@@ tphi =")[1:]:
      tphi += [evalnum(f) for f in xxx.split("\n")[0].strip().split()]
   rgroup = []
   yyy = headerdata.split('#@@   rgroup   =')[1].split('\n')[0]
   for y in yyy.split():
      rgroup.append(evalnum(y))
   #drphi = [evalnum(f) for f in headerdata.split("#@@ drion/dphi =")[1].split("\n")[0].strip().split()]


   ## extract the potential
   if (theory=='dft'):  str = "Total DFT energy"
   if (theory=='pspw'): str = "Total PSPW energy"
   if (theory=='mp2'):  str = "Total MP2 energy"
   if (theory=='scf'):  str = "Total SCF energy"
   if (theory=='tce'):  str = "CCSD(T) total energy / hartree"
   if (theory=='ccsd(t)'):  str = "Total CCSD(T) energy:"
   if (theory=='ccsd'):  str = "Total CCSD energy:"
   potential = []
   with open(filename,'r') as ofile:
      for line in ofile:
         if (line.find(str) != -1):
            split = line.split()
            if (theory=='mp2'):
               potential.append(evalnum(split[3]))
            elif (theory=='ccsd(t)'):
               potential.append(evalnum(split[3]))
            elif (theory=='tce'):
               potential.append(evalnum(split[6]))
            else:
               potential.append(evalnum(split[4]))


   if (theory=='pspw') and (len(potential) > nphi): 
      nphi0 = len(potential)
      shift = nphi0-nphi
      potential = potential[shift:]

   ## calculate Cannonical Formula Results for Hindered Rotation ##
   if ((nphi > 0) and (len(potential) == nphi)):
      V0 = potential[0]
      Vr = resize(0.0,nphi)
      for i in range(nphi):
         Vr[i] = potential[i] - V0

      ## increase grid by doubling - Crude interpolation ##
      Nmax = nphi
      while ((2*Nmax) < NNmax):
         tmp = resize(Vr,Nmax)
         Vr  = resize(0.0,2*Nmax)
         for i in range(Nmax):
            Vr[2*i] = tmp[i]
         for i in range(Nmax-1):
            Vr[2*i+1] = 0.5*(tmp[i]+tmp[i+1])
         Vr[2*Nmax-1] = 0.5*(tmp[Nmax-1]+tmp[0])
         Nmax = 2*Nmax
      Vk = fft(Vr)
      Vk = Vk/Nmax
     

      H = resize(array(0.0,complex),(Nmax,Nmax))
      krange = range(Nmax)
      for i in range(Nmax): krange[i] -= (Nmax/2-1)

      for kj in krange:
         for ki in krange:
            i = ki
            j = kj
            indx = ki-kj
            if (i<0): i = i + Nmax
            if (j<0): j = j + Nmax
            if (indx<0): indx = indx + Nmax
            H[i][j] = Vk[indx]

      for ki in krange:
         i = ki
         if (i < 0): i = i + Nmax
         H[i][i] = H[i][i] + (0.5/Im)*ki*ki


      (ees,vvs) = eig(H) 
      eigs = real(ees)

      Q  = 0.0
      Qp = 0.0
      for i in range(Nmax):
        em = eigs[i]*627.51*1000.0   # convert to calories #
        Q  = Q  +  exp(-em/(R*T))
        Qp = Qp +  em*exp(-em/(R*T))
      Qp = 1.0/(R*T*T)*Qp
      S  = R*log(Q)  + (R*T/Q)*Qp - R*log(sym_num)
      Uf = R*T*T*Qp/Q


      ### extract frequencies ###
      all_lines2 = freq_blob.split("\n")
      freqs = []
      for line in all_lines2:
         if (line.find("P.Frequency") != -1):
            freqs += [ evalnum(s) for s in line.split()[1:]]


      mysum1 = [0.0]*len(freqs)
      xx = odata.split()
      if (len(xx)==1):
         fnum = evalnum(xx[0])
         mysum1[fnum-1] = 1.0
         hrotoroverlapset = True
      elif (len(xx)>1):
         for n in range(len(xx)/2):
            fnum = evalnum(xx[2*n])
            fwww = evalnum(xx[2*n+1])
            mysum1[fnum-1] = fwww
         hrotoroverlapset = True
      else:
         hrotoroverlapset = False
      
      minfreq = 0.1
      if hrotoroverlapset: 
         fstr = '#@@ Frequency Weights for Hindered Rotation (manually set):' + eoln
      else:
         fstr = '#@@ Frequency Overlap Results for Hindered Rotation:' + eoln
      wwn =  []
      wwp =  []
      wwz =  []
      smax = 0.0
      isnegative = False
      for fnum in range(len(freqs)):
         (w,v) = get_frequency(freq_blob,fnum+1)
         if (hrotoroverlapset):
            sum1 = mysum1[fnum]
         else:
            sum1 = w_freq_hrotor(rgroup,tphi,v)
         #fstr += "#@@ %d  w=%.3f <drphi|freq>=%.3f\n" % (fnum,w,sum1)
         if (w<(-0.01)):
            wwn.append([w,sum1,0.0])
            if ((sum1*sum1)>smax):
               smax = sum1*sum1
               isnegative = True
               fnumn = fnum
         elif (w>(minfreq)): 
            wwp.append([w,sum1,0.0])
            if ((sum1*sum1)>smax):
               smax = sum1*sum1
               isnegative = False
         else:
            wwz.append([w,sum1,0.0])

      if (isnegative):
         Ecorrect = Uf/(1000.0*23.06*27.2116)
         Scorrect = S/(1000.0*23.06*27.2116)
         Evib = 0.0
         Svib = 0.0
         wwn[fnumn][2] = 1.0
      else:
         norm = 0.0
         for i in range(len(wwp)): norm += wwp[i][1]*wwp[i][1]
         if (norm>1.0e-12):
            norm1 = 1.0/sqrt(norm)
         else:
            norm1 = 0.0
         for i in range(len(wwp)): wwp[i][2] = wwp[i][1]*norm1
         normmax = 0.0
         for i in range(len(wwp)): 
            if ((wwp[i][2]**2)>normmax): 
               normmax = wwp[i][2]**2
         if (normmax<0.3) and (not hrotorforce):
            Ecorrect = 0.0
            Scorrect = 0.0
            Evib = 0.0
            Svib = 0.0
         else:
            Ecorrect = Uf/(1000.0*23.06*27.2116)
            Scorrect = S/(1000.0*23.06*27.2116)
            Evib = 0.0
            Svib = 0.0
            for i in range(len(wwp)): 
               (etmp,stmp) = analyze_frequency(wwp[i][0])
               Ecorrect -= wwp[i][2]*wwp[i][2]*etmp
               Scorrect -= wwp[i][2]*wwp[i][2]*stmp
               Evib += wwp[i][2]*wwp[i][2]*etmp
               Svib += wwp[i][2]*wwp[i][2]*stmp

      jn = 0
      jp = 0
      jz = 0
      if hrotoroverlapset:
        for fnum in range(len(freqs)):
           w = freqs[fnum]
           if (w<(-0.01)):
              fstr += "#@@ %5d  w=%.3f \t weight=%.3f\n" % (fnum,w,wwn[jn][2]**2)
              jn += 1
           elif (w>(minfreq)): 
              fstr += "#@@ %5d  w=%.3f \t weight=%.3f\n" % (fnum,w,wwp[jp][2]**2)
              jp += 1
           else:
              fstr += "#@@ %5d  w=%.3f \t weight=%.3f\n" % (fnum,w,wwz[jz][2]**2)
              jz += 1
      else:
        for fnum in range(len(freqs)):
           w = freqs[fnum]
           if (w<(-0.01)):
              fstr += "#@@ %5d  w=%.3f \t drphit*freq=%.3f \t weight=%.3f\n" % (fnum,w,wwn[jn][1],wwn[jn][2]**2)
              jn += 1
           elif (w>(minfreq)): 
              fstr += "#@@ %5d  w=%.3f \t drphit*freq=%.3f \t weight=%.3f\n" % (fnum,w,wwp[jp][1],wwp[jp][2]**2)
              jp += 1
           else:
              fstr += "#@@ %5d  w=%.3f \t drphit*freq=%.3f \t weight=%.3f\n" % (fnum,w,wwz[jz][1],wwz[jz][2]**2)
              jz += 1
         

      tstr =  '#@@@@@@@@@@@@@@@@@@@@@@@@ START ROTOR @@@@@@@@@@@@@@@@@@@@@@@@@@' + eoln
      tstr +=  '#@@' + eoln
      tstr +=  headerdata
      tstr +=  '#@@' + eoln
      tstr +=  '#@@ Cannonical Formula Results for Hindered Rotation:' + eoln
      tstr +=  '#@@    Nmax   = %18d ' % (Nmax) + eoln
      tstr +=  '#@@    T      = %18.3f K' % (T) + eoln
      tstr +=  '#@@    sigma  = %18.6f' % (sym_num) + eoln
      tstr +=  '#@@    Im     = %18.6f' % (Im) + eoln
      tstr +=  '#@@    Qf     = %18.6f' % (Q) + eoln
      tstr +=  '#@@    dQf/dT = %18.6f 1/K' % (Qp) + eoln
      tstr +=  '#@@    Uf     = %18.6f kcal/mol (%18.6f au)' % (Uf/1000.0,Uf/(1000.0*23.06*27.2116)) + eoln
      tstr +=  '#@@    Sf     = %18.6f cal/mol-K' % (S) + eoln
      tstr +=  '#@@' + eoln
      tstr +=  '#@@    Uvib(bad)= %18.6f kcal/mol  (%18.6f au)' % (Evib*23.06*27.2116,Evib) + eoln
      tstr +=  '#@@    Svib(bad)= %18.6f cal/mol-K (%18.6f au)' % (Svib*1000*23.06*27.2116,Svib) + eoln
      tstr +=  '#@@' + eoln
      if (hrotorzero):
         tstr +=  '#@@ Setting hrotor correction to zero' + eoln
         Ecorrect = 0.0
         Scorrect = 0.0
      tstr +=  '#@@    Ucorrect = %18.6f kcal/mol  (%18.6f au)' % (Ecorrect*23.06*27.2116,Ecorrect) + eoln
      tstr +=  '#@@    Scorrect = %18.6f cal/mol-K (%18.6f au)' % (Scorrect*1000*23.06*27.2116,Scorrect) + eoln

      tstr +=  '#@@' + eoln
      tstr +=  fstr
      tstr +=  '#@@' + eoln
      tstr +=  '#@@    hindered potential ='
      for p in potential:
         tstr += " %.6f" % p
      tstr +=  eoln
      tstr +=  '#@@' + eoln
      tstr +=  '#@@@@@@@@@@@@@@@@@@@@@@@@ END ROTOR   @@@@@@@@@@@@@@@@@@@@@@@@@@' + eoln
      

   return tstr


def replace_hrotor_blob(hrotors_blob,hrotor_blob):
   eoln = '\n'
   bstr =  '#@@@@@@@@@@@@@@@@@@@@@@@@ START ROTOR @@@@@@@@@@@@@@@@@@@@@@@@@@' + eoln
   estr =  '#@@@@@@@@@@@@@@@@@@@@@@@@ END ROTOR   @@@@@@@@@@@@@@@@@@@@@@@@@@' + eoln
   rrr = hrotor_blob.split(bstr)[1].split(estr)[0]
   xxx = '#@@   rbond    =' + hrotor_blob.split('#@@   rbond    =')[1].split('\n')[0]
   yyy = '#@@   rgroup   =' + hrotor_blob.split('#@@   rgroup   =')[1].split('\n')[0]
   for aaa in hrotors_blob.split(bstr)[1:]:
      bbb = aaa.split(estr)[0]
      if (xxx in bbb) and (yyy in bbb):
         hrotors_blob = hrotors_blob.replace(bbb,rrr)

   return hrotors_blob

      


###############################################
#                                             #
#            insert_abbreviation              #
#                                             #
###############################################

def insert_abbreviation(hup,dbfile,abrev_table,abbreviation, 
                        iupac,mformula,InChI,InChIKey,cid,cas,kegg,synonyms, 
                        smiles,csmiles,esmiles,charge,mult,xyz_blob, 
                        chemical_structure_asciiart,bonding_string,covalent_string,optimized):
#
#+-----------------------------+---------+------+-----+---------+----------------+
#| Field                       | Type    | Null | Key | Default | Extra          |
#+-----------------------------+---------+------+-----+---------+----------------+
#| Id                          | int(11) | NO   | PRI | NULL    | auto_increment |
#| abbreviation                | text    | YES  |     | NULL    |                |
#| iupac                       | text    | YES  |     | NULL    |                |
#| mformula                    | text    | YES  |     | NULL    |                |
#| InChI                       | text    | YES  |     | NULL    |                |
#| smiles                      | text    | YES  |     | NULL    |                |
#| csmiles                     | text    | YES  |     | NULL    |                |
#| esmiles                     | text    | YES  |     | NULL    |                |
#| charge                      | int(11) | YES  |     | NULL    |                |
#| mult                        | int(11) | YES  |     | NULL    |                |
#| xyz_blob                    | blob    | YES  |     | NULL    |                |
#| InChIKey                    | text    | YES  |     | NULL    |                |
#| synonyms                    | text    | YES  |     | NULL    |                |
#| cid                         | text    | YES  |     | NULL    |                |
#| cas                         | text    | YES  |     | NULL    |                |
#| kegg                        | text    | YES  |     | NULL    |                |
#| chemical_structure_asciiart | text    | YES  |     | NULL    |                |
#| bonding_string              | text    | YES  |     | NULL    |                |
#| covalent_string             | text    | YES  |     | NULL    |                |
#| optimized                   | text    | YES  |     | NULL    |                |
#+-----------------------------+---------+------+-----+---------+----------------+

#   if ("." in smiles):
#      print("insert_abbreviation: dot in smiles...not adding to abbreviation table")
#      return

   if (hup=='sqlite3'):
      issqlite3 = True
   else:
      issqlite3 = False

   sqlinsert = "insert into " + abrev_table
   sqlinsert += " (abbreviation,iupac,mformula,InChI,InChIKey,"
   sqlinsert += "cid,cas,kegg,synonyms,smiles,"
   sqlinsert += "csmiles,esmiles,charge,mult,xyz_blob,"
   sqlinsert += "chemical_structure_asciiart,bonding_string,covalent_string,optimized) values ("
   sqlinsert += "?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);"
   if (not issqlite3): sqlinsert = sqlinsert.replace('?','%s')
   insertlist = []
   insertlist.append(abbreviation)
   insertlist.append(iupac)
   insertlist.append(mformula)
   insertlist.append(InChI)
   insertlist.append(InChIKey)

   insertlist.append(cid)
   insertlist.append(cas)
   insertlist.append(kegg)
   insertlist.append(synonyms)
   insertlist.append(smiles)

   insertlist.append(csmiles)
   insertlist.append(esmiles)
   insertlist.append(charge)
   insertlist.append(mult)
   insertlist.append(xyz_blob)

   insertlist.append(chemical_structure_asciiart)
   insertlist.append(bonding_string)
   insertlist.append(covalent_string)
   if optimized:
      insertlist.append("yes")
   else:
      insertlist.append("no")
  
   sqlcheck = "select count(1) from " + abrev_table + " where "
   sqlcheck += "iupac=? and InChI=? and InChIKey=? and smiles=? and csmiles=? and esmiles=? and "
   sqlcheck += "charge=? and mult=? and bonding_string=? and covalent_string=? limit 1;"
   if (not issqlite3): sqlcheck = sqlcheck.replace('?','%s')
   checklist = []
   checklist.append(iupac)
   checklist.append(InChI)
   checklist.append(InChIKey)
   checklist.append(smiles)
   checklist.append(csmiles)
   checklist.append(esmiles)
   checklist.append(charge)
   checklist.append(mult)
   checklist.append(bonding_string)
   checklist.append(covalent_string)

   sqlcheck2 = "select count(1) from " + abrev_table + " where "
   sqlcheck2 += "iupac=? and InChI=? and InChIKey=? and smiles=? and csmiles=? and esmiles=? and "
   sqlcheck2 += "charge=? and mult=? and bonding_string=? and covalent_string=? and xyz_blob=? limit 1;"
   if (not issqlite3): sqlcheck2 = sqlcheck2.replace('?','%s')
   checklist2 = []
   checklist2.append(iupac)
   checklist2.append(InChI)
   checklist2.append(InChIKey)
   checklist2.append(smiles)
   checklist2.append(csmiles)
   checklist2.append(esmiles)
   checklist2.append(charge)
   checklist2.append(mult)
   checklist2.append(bonding_string)
   checklist2.append(covalent_string)
   checklist2.append(xyz_blob)

   if (issqlite3):
      dbcon = sqlite3.connect(dbfile)
   else:
      host = hup.split()[0]
      user = hup.split()[1]
      pss = hup.split()[2]
      #dbcon = MySQLdb.connect(host,user,pss,dbfile)
      dbcon = MySQLdb.connect(host=host,user=user,password=pss,database=dbfile,autocommit=True,charset='utf8mb4')
   
   with dbcon:
      cur = dbcon.cursor()
      cur.execute(sqlcheck,checklist)
      row = cur.fetchone()

      duplicate = (row[0]>0)
      if ((not duplicate) or (optimized)):
         cur.execute(sqlcheck2,checklist2)
         row2 = cur.fetchone()

         duplicate2 = (row2[0]>0)
         if (not duplicate2):
            print("inserting into " + abrev_table)
            cur.execute(sqlinsert,insertlist)






def parse_cube_files(nwchem_output_file):
    """
    Parses an NWChem output file to extract cube file names for different densities.

    Args:
        nwchem_output_file (str): Path to the NWChem output file.

    Returns:
        dict: A dictionary mapping density types to their respective cube file names.
    """
    cube_files = {}

    # Define patterns for each density type
    patterns = {
        "difference": r"writing difference density to filename:\s*(\S+)",
        "alpha": r"writing alpha density to filename:\s*(\S+)",
        "beta": r"writing beta density to filename:\s*(\S+)",
        "total": r"writing total density to filename:\s*(\S+)"
    }

    with open(nwchem_output_file, "r") as file:
        for line in file:
            for key, pattern in patterns.items():
                match = re.search(pattern, line)
                if match:
                    cube_files[key] = match.group(1)

    return cube_files


def validate_cube_files(nwchem_output_file, extradata_files):
    """
    Parses an NWChem output file to extract cube file names and checks if they exist in extradata_files.

    Args:
        nwchem_output_file (str): Path to the NWChem output file.
        extradata_files (str): A string containing a list of available filenames.

    Returns:
        dict: A dictionary indicating whether each cube file is found in extradata_files.
    """
    # Parse the cube files from the NWChem output
    cube_files = parse_cube_files(nwchem_output_file)

    # Convert extradata_files string into a set of filenames
    available_files = set(extradata_files.split())

    # Check if each cube file is in extradata_files
    validation_results = {}
    for key, filename in cube_files.items():
        validation_results[key] = filename in available_files

    return validation_results



def are_all_cube_files_present(nwchem_output_file, extradata_files):
    """
    Parses an NWChem output file to extract cube file names and checks if all required cube files exist in extradata_files.

    Args:
        nwchem_output_file (str): Path to the NWChem output file.
        extradata_files (str): A string containing a list of available filenames.

    Returns:
        bool: True if all cube files are present, False otherwise.
        list: List of missing cube files (if any).
    """
    # Parse the cube files from the NWChem output
    cube_files = parse_cube_files(nwchem_output_file)

    # Convert extradata_files string into a set of filenames
    available_files = set(extradata_files.split())

    # Determine missing files
    missing_files = [filename for filename in cube_files.values() if filename not in available_files]

    # Return True if all files are present, otherwise False with the missing files list
    return len(missing_files) == 0, missing_files



def get_full_cube_filenames(jjjj, extradata_files):
    """
    Finds the complete filenames in extradata_files that match cube file names from jjjj.

    Args:
        jjjj (dict): Dictionary containing expected cube file names (e.g., {'difference': 'diff.cube', ...}).
        extradata_files (str): A space-separated string containing all available filenames.

    Returns:
        dict: A dictionary mapping cube file types (difference, alpha, beta, total) to their full filenames.
    """
    # Convert extradata_files into a list of filenames
    available_files = extradata_files.split()

    # Map cube file types to their complete filenames
    full_filenames = {}

    for key, filename in jjjj.items():
        # Find the full filename that matches the expected filename
        matching_files = [f for f in available_files if filename in f]

        # If a match is found, store it
        if matching_files:
            full_filenames[key] = matching_files[0]  # Take the first match

    return full_filenames



def extract_atom_names_from_cube(cube_filename):
    """
    Parses a Gaussian Cube file to extract atom names based on atomic numbers.

    Args:
        cube_filename (str): Path to the Gaussian Cube file.

    Returns:
        dict: Dictionary mapping atom indices (starting from 1) to atom names (symbols).
    """
    atom_names = {}
    
    # Complete Periodic Table Mapping (Atomic Number -> Element Symbol)
    periodic_table = {
        1: "H",  2: "He", 3: "Li", 4: "Be", 5: "B", 6: "C", 7: "N", 8: "O", 9: "F", 10: "Ne",
        11: "Na", 12: "Mg", 13: "Al", 14: "Si", 15: "P", 16: "S", 17: "Cl", 18: "Ar",
        19: "K",  20: "Ca", 21: "Sc", 22: "Ti", 23: "V", 24: "Cr", 25: "Mn", 26: "Fe", 27: "Co", 28: "Ni",
        29: "Cu", 30: "Zn", 31: "Ga", 32: "Ge", 33: "As", 34: "Se", 35: "Br", 36: "Kr",
        37: "Rb", 38: "Sr", 39: "Y",  40: "Zr", 41: "Nb", 42: "Mo", 43: "Tc", 44: "Ru", 45: "Rh", 46: "Pd",
        47: "Ag", 48: "Cd", 49: "In", 50: "Sn", 51: "Sb", 52: "Te", 53: "I",  54: "Xe",
        55: "Cs", 56: "Ba", 57: "La", 58: "Ce", 59: "Pr", 60: "Nd", 61: "Pm", 62: "Sm", 63: "Eu", 64: "Gd",
        65: "Tb", 66: "Dy", 67: "Ho", 68: "Er", 69: "Tm", 70: "Yb", 71: "Lu",
        72: "Hf", 73: "Ta", 74: "W",  75: "Re", 76: "Os", 77: "Ir", 78: "Pt", 79: "Au", 80: "Hg",
        81: "Tl", 82: "Pb", 83: "Bi", 84: "Po", 85: "At", 86: "Rn",
        87: "Fr", 88: "Ra", 89: "Ac", 90: "Th", 91: "Pa", 92: "U",  93: "Np", 94: "Pu", 95: "Am", 96: "Cm",
        97: "Bk", 98: "Cf", 99: "Es", 100: "Fm", 101: "Md", 102: "No", 103: "Lr",
        104: "Rf", 105: "Db", 106: "Sg", 107: "Bh", 108: "Hs", 109: "Mt", 110: "Ds", 111: "Rg",
        112: "Cn", 113: "Nh", 114: "Fl", 115: "Mc", 116: "Lv", 117: "Ts", 118: "Og"
    }

    with open(cube_filename, "r") as file:
        lines = file.readlines()

        # The third line contains the number of atoms
        num_atoms = int(lines[2].split()[0])  # First value in the third line
        
        # Atom data starts at line 6, extract each atom
        for i in range(num_atoms):
            parts = lines[6 + i].split()
            atomic_number = int(parts[0])  # Atomic number (first column)
            atom_names[i + 1] = periodic_table.get(atomic_number, "Unknown")  # Map to symbol

    return atom_names





def extract_bader_charges(acf_text):
    """
    Extracts Bader charges from ACF.dat file content.

    Args:
        acf_text (str): Content of the ACF.dat file as a string.

    Returns:
        dict: A dictionary mapping atom numbers to Bader charges (floats).
    """
    bader_charges = {}

    for line in acf_text.splitlines():
        match = re.match(r"\s*(\d+)\s+([-.\d]+)\s+([-.\d]+)\s+([-.\d]+)\s+([-.\d]+)", line)
        if match:
            atom_number = int(match.group(1))  # Atom number
            charge = float(match.group(5))  # Bader charge
            bader_charges[atom_number] = charge

    return bader_charges


def compute_bader_magnetization(alpha_bader, beta_bader, atom_names):
    """
    Computes the magnetization (alpha charge - beta charge) for each atom and includes atom names.

    Args:
        alpha_bader (dict): Dictionary of alpha Bader charges with atom numbers as keys.
        beta_bader (dict): Dictionary of beta Bader charges with atom numbers as keys.
        atom_names (dict): Dictionary mapping atom numbers to atom names.

    Returns:
        dict: A dictionary mapping atom numbers to a tuple (atom name, magnetization value).
    """
    magnetization = {}

    for atom_number in alpha_bader.keys():
        if atom_number in beta_bader:
            magnetization[atom_number] = (atom_names.get(atom_number, "Unknown"), 
                                          alpha_bader[atom_number] - beta_bader[atom_number])
        else:
            print(f"Warning: Atom {atom_number} is missing in beta Bader charges!")

    return magnetization









def print_wannier_table(wannier_data, wannier_magnetization):
    """
    Prints a formatted table of Wannier data and magnetization.

    Args:
        wannier_data (dict): Dictionary containing atom types and spin counts.
        wannier_magnetization (dict): Dictionary containing Wannier magnetization values.
    """
    print(f"{'Atom':<6} {'Type':<4} {'Wannier Up':<12} {'Wannier Down':<14} {'Wannier Magnetization':<20}")
    print("=" * 60)
    
    for atom_id in sorted(wannier_data.keys()):
        atom_type = wannier_data[atom_id]['type']
        up = wannier_data[atom_id]['up']
        down = wannier_data[atom_id]['down']
        magnetization = wannier_magnetization[atom_id]['wannier_magnetization']
        
        print(f"{atom_id:<6} {atom_type:<4} {up:<12} {down:<14} {magnetization:<20}")


def print_dly_table(dly_data, dly_magnetization):
    """ 
    Prints a formatted table of dly data and magnetization.

    Args:
        dly_data (dict): Dictionary containing atom types and spin counts.
        dly_magnetization (dict): Dictionary containing dly magnetization values.
    """
    print(f"{'Atom':<6} {'Type':<4} {'DLY Up':<12} {'DLY Down':<14} {'DLY Magnetization':<20}")
    print("=" * 60)
    
    for atom_id in sorted(dly_data.keys()):
        atom_type = dly_data[atom_id]['type']
        up = dly_data[atom_id]['up']
        down = dly_data[atom_id]['down']
        magnetization = dly_magnetization[atom_id]['wannier_magnetization']
        
        print(f"{atom_id:<6} {atom_type:<4} {up:<12} {down:<14} {magnetization:<20}")




def print_bader_analysis(bader_alpha, bader_beta, bader_total, bader_magnetization):
    """
    Prints a formatted table of Bader alpha, beta, total charges, and magnetization.

    Args:
        bader_alpha (dict): Mapping of atom index to Bader alpha charge.
        bader_beta (dict): Mapping of atom index to Bader beta charge.
        bader_total (dict): Mapping of atom index to total Bader charge.
        bader_magnetization (dict): Mapping of atom index to (Element Symbol, Bader Magnetization) tuple.
    """
    print("\n=== Bader Charge and Magnetization Analysis ===")
    print(f"{'Atom #':<8}{'Element':<8}{'Alpha Charge':<15}{'Beta Charge':<15}{'Total Charge':<15}{'Bader Mag':<15}")
    print("=" * 80)

    for atom_id in sorted(bader_total.keys()):
        alpha_charge = bader_alpha.get(atom_id, 0.0)
        beta_charge = bader_beta.get(atom_id, 0.0)
        total_charge = bader_total.get(atom_id, 0.0)
        bader_entry = bader_magnetization.get(atom_id, ("Unknown", 0.0))

        if isinstance(bader_entry, tuple) and len(bader_entry) == 2:
            element, bader_mag = bader_entry
        else:
            element, bader_mag = "Unknown", 0.0  # Handle missing or incorrect data gracefully

        print(f"{atom_id:<8}{element:<8}{alpha_charge:<15.4f}{beta_charge:<15.4f}{total_charge:<15.4f}{bader_mag:<15.4f}")

    print("=" * 80)


def print_both_magnetization(wannier_data, wannier_magnetization, bader_magnetization):
    """
    Prints both Wannier and Bader magnetization for each atom.

    Args:
        wannier_data (dict): Dictionary containing atom types.
        wannier_magnetization (dict): Mapping of atom index to Wannier magnetization (float).
        bader_magnetization (dict): Mapping of atom index to (Element Symbol, Bader Magnetization) tuple.
    """
    print("\n=== Wannier and Bader Magnetization per Atom ===")
    print(f"{'Atom #':<8}{'Element':<8}{'Wannier Mag':<15}{'Bader Mag':<15}")
    print("=" * 50)

    for atom_id in sorted(set(wannier_magnetization.keys()) | set(bader_magnetization.keys())):
        # Ensure atom_id exists in both dictionaries
        wannier_mag = wannier_magnetization.get(atom_id, {}).get('wannier_magnetization', 0.0)
        bader_entry = bader_magnetization.get(atom_id, ("Unknown", 0.0))
        
        if isinstance(bader_entry, tuple) and len(bader_entry) == 2:
            element, bader_mag = bader_entry
        else:
            element, bader_mag = "Unknown", 0.0  # Handle incorrect format gracefully

        print(f"{atom_id:<8}{element:<8}{wannier_mag:<15.4f}{bader_mag:<15.4f}")

    print("=" * 50)



def clean_input(nwinput_str):
    """Removes comments and empty lines from the input file."""
    return "\n".join(line.split("#")[0].strip() for line in nwinput_str.splitlines() if line.strip())

def parse_geometry(nwinput_str):
    """Extracts atomic coordinates and unit cell information from the geometry block."""
    if "geometry" not in nwinput_str:
        return ""

    geometry_blk = nwinput_str.split("geometry", 1)[1]
    lattice_blk = ""

    if "system crystal" in geometry_blk:
        lattice_blk, geometry_blk = geometry_blk.split("end", 1)
    else:
        geometry_blk = geometry_blk.split("end", 1)[0]

    atom_lines = [line.strip() for line in geometry_blk.split("\n") if line.strip()]

    #  Ensure only atom coordinates are in `fractionaldata{}` (Remove `task` commands)
    valid_atoms = [line.split() for line in atom_lines if len(line.split()) == 4 and "task" not in line.lower()]

    xyz_data = [f"{symb} {x} {y} {z}" for symb, x, y, z in valid_atoms]

    if lattice_blk:
        lattice_lines = [line.strip() for line in lattice_blk.split("\n") if line.strip()]
        lattice = " | ".join(lattice_lines[1:])  # Skip 'lattice_vectors' line
        geometry = f"fractionaldata{{{' | '.join(xyz_data)}}} unitcell{{{lattice}}}"
    else:
        geometry = f"xyzdata{{{' | '.join(xyz_data)}}}"

    return geometry

def parse_nwpw_block(nwinput_str):
    """Parses the `nwpw` block for xc, mult, cutoff, pspspin, and uterm values."""
    nwinput_str = clean_input(nwinput_str)

    match = re.search(r"nwpw(.*?)end\s*\n", nwinput_str, re.DOTALL | re.IGNORECASE)
    if not match:
        return ""

    nwpw_block = match.group(1).strip()
    output = []

    patterns = {
        "xc": r"\bxc\s+(\S+)",
        "mult": r"\bmult\s+(\d+)",
        "cutoff": r"\bcutoff\s+([\d\.]+)"
    }

    for key, pattern in patterns.items():
        match = re.search(pattern, nwpw_block, re.IGNORECASE)
        if match:
            value = match.group(1).strip()
            output.append(f"{key}{{{value}}}" if key != "cutoff" else f"basis{{{value}}}")

    # Extract pspspin up/down
    pspspin_up = re.findall(r"pspspin\s+up\s+d\s+(-?\d+\.?\d*)\s+([\d\s:]+)", nwpw_block, re.IGNORECASE)
    pspspin_down = re.findall(r"pspspin\s+down\s+d\s+(-?\d+\.?\d*)\s+([\d\s:]+)", nwpw_block, re.IGNORECASE)

    if pspspin_up:
        spin_value, indices = pspspin_up[0]
        output.append(f"pspspin{{up d {spin_value} {indices.strip()}}}")

    if pspspin_down:
        spin_value, indices = pspspin_down[0]
        output.append(f"pspspin{{down d {spin_value} {indices.strip()}}}")

    # Extract `uterm` values
    #uterms = re.findall(r"uterm d (.*?)\n", nwpw_block, re.IGNORECASE)
    uterms = re.findall(r"uterm\s+d\s+([\d\.\s:]+)", nwpw_block, re.IGNORECASE | re.MULTILINE)
    for uterm in uterms:
        output.append(f"uterm{{d {uterm.strip()}}}")

    return " ".join(output)

def parse_dplot(nwinput_str):
    """Extracts the `dplot` block and formats it for `pspw_dplot{}` inside `calculation_type{}`."""
    dplot_match = re.search(r"dplot(.*?)end", nwinput_str, re.DOTALL | re.IGNORECASE)
    if not dplot_match:
        return ""

    dplot_block = dplot_match.group(1).strip()
    densities = re.findall(r"density\s+(\w+)\s+([\w\.]+)", dplot_block, re.IGNORECASE)

    if not densities:
        return ""

    dplot_entries = [f"density {density} {file}" for density, file in densities]
    return f"pspw_dplot{{{' | '.join(dplot_entries)}}}"

def parse_calculation(nwinput_str):
    """Parses task commands, set commands, and embeds dplot inside `calculation_type{}` while maintaining the order."""
    tasks = nwinput_str.split("task")
    calculations = []
    #set_commands = []
    include_pspspin_off = False
    dplot_entry = parse_dplot(nwinput_str)

    # Step 2: Process tasks **IN ORIGINAL ORDER**
    for task in tasks[1:]:  # Skip the first split part before 'task'
        lines = task.strip().split("\n")
        first_line = lines[0].strip()
        calc_type = first_line.replace("pspw ", "").replace("ignore", "").strip()

        if calc_type == "pspw_dplot" and dplot_entry:
            calculations.append(dplot_entry)
        elif calc_type and calc_type != "pspw_dplot":
            calculations.append(calc_type)

        # Extract `set` commands before second and later tasks
        for line in lines:
            if line.startswith("set "):
                calculations.append(f"set{{{line[4:].strip()}}}")
            if line.startswith("uterm "):
                calculations.append("uterm{" + line.replace("uterm","").strip()+"}")
            if line.startswith("pspspin off"):
                calculations.append("pspspin{off}")

        #if calc_type == "pspw_dplot" and dplot_entry:
        #    calculations.append(dplot_entry)
        #elif calc_type and calc_type != "pspw_dplot":
        #    calculations.append(calc_type)

    return f"calculation_type{{{'-'.join(calculations)}}}" if calculations else "calculation_type{}"

def parse_theory(file_path):
    """Determines the theory used (pspw or band). Default to pspw for NWPW calculations."""
    theory = '????'
    with open(file_path,'r') as ff:
       nwinput_str = ff.read()
       if "BAND Calculation" in nwinput_str.lower():
          theory = "theory{band}"
       else:
          theory = "theory{pspw}"

    return theory



def extract_calculation_genome(file_path):
    """
    Extracts the calculation genome from a structured comment block in a file.

    Parameters:
        file_path (str): Path to the input file.

    Returns:
        str: The extracted calculation genome, or 'Unknown' if not found.
    """
    try:
        with open(file_path, 'r') as file:
            for line in file:
                match = re.search(r"#\s*genome\s*[-:]\s*(\S+)", line, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
    except Exception as e:
        print(f"Error reading file: {e}")

    return "Unknown"









###############################################
#                                             #
#            insert_solid_calculation         #
#                                             #
###############################################

def insert_solid_calculation(outfile,hup,dbfile,table,bad_table,abrev_table,nwpassword,nwmachine,extra_datafiles,noresubmit):

  if (hup=='sqlite3'):
      issqlite3 = True
  else:
      issqlite3 = False

  tt1 = time.localtime()
  dd1 = "-%d-%d-%d-%d:%d:%d" % (tt1[0],tt1[1],tt1[2],tt1[3],tt1[4],tt1[5])

  smilefile = wrkdir + "/"+tmpsmi3
  xyzfile2  = wrkdir + "/"+tmpxyz1
  xyzfile   = wrkdir + "/"+tmpxyz2
  outfile_without_hash  = wrkdir + "/"+outfile99

  myjob = {}
  myjob['xyz'] = " "
  myjob['cif'] = " "
  myjob['theory'] = " "
  myjob['datetime'] = " "
  myjob['k_point_grid'] = " "
  myjob['smearing_type'] = " "
  myjob['smearing_width'] = " "
  myjob['calculation_type'] = " "
  myjob['genome'] = " "
  myjob['machine'] = " "
  myjob['ncpu'] = " "
  myjob['wall_time'] = " "
  myjob['pseudopotentials'] = " "
  myjob['material_name'] = " "
  myjob['lattice_parameters'] = " "
  myjob['lattice_type'] = " "
  myjob['space_group'] = " "
  myjob['basis'] = " "
  myjob['energy'] = " "
  myjob['enthalpy'] = " "
  myjob['entropy'] = " "
  myjob['hubbaard_U'] = " "
  myjob['initial_magnetic_moment'] = " "
  myjob['wannier_charges'] = False
  myjob['bader_charges'] = False
 
  
  print("extra_datafiles=", extra_datafiles)


  if (os.path.exists(outfile)):
    #if (parse_jobfinished(outfile)):
    
      with open(outfile,'r') as ff:
         aa = ff.read()
     
      aa = aa.replace('#','')
      
      with open(outfile_without_hash,'w') as ff:
         ff.write(aa)

      nwfilename = nwmachine + "/" + outfile[outfile.rfind('/')+1:] + dd1

      ### remove "," from filename since archive cannot handle this ###
      nwfilename = nwfilename.replace(",","-")  

      ### add yaml file ###
      myjob['theory'] = parse_theory(outfile)
      myjob['genome'] = extract_calculation_genome(outfile)

      myjob['datetime'] = parse_job_info_datetime(outfile_without_hash)

      myjob['jobok']    = parse_calculation_ok(outfile_without_hash)
      myjob['program']  = parse_program(outfile_without_hash)
      myjob['machine']  = parse_machine(outfile_without_hash)
      myjob['ncpu']     = parse_ncpu(outfile_without_hash)
      myjob['wall_time']= parse_wall_time(outfile_without_hash)
      #myjob['energy']   = parse_energy(outfile_without_hash)
      myjob['enthalpy'] = parse_enthalpy(outfile_without_hash)
      myjob['entropy']  = parse_entropy(outfile_without_hash)

      myjob['charge'] = parse_charge(outfile_without_hash)
      myjob['mult']   = parse_mult(outfile_without_hash)

      myjob['spin_penalty'] = parse_spin_penalty(outfile_without_hash)
      print("Spin penalty parsed:", myjob['spin_penalty'])
      myjob['initial_magnetic_moments'] = apply_spin_penalty(compute_magnetic_moments_nwout(outfile_without_hash), myjob['spin_penalty'])



      myjob['xc']     = parse_xc(outfile)
      myjob['basis']  = parse_basis(False,outfile)

      myjob['pseudopotentials'] =  parse_detailed_pseudopotentials(outfile_without_hash)

      raw_unitcell = parse_unitcell_calculation(outfile_without_hash)
      print("raw=",raw_unitcell)
      myjob['unitcell'] = convert_unitcell_to_angstrom(parse_unitcell_from_string(raw_unitcell))
      print("unitcell=",myjob['unitcell']);
      myjob['lattice_parameters']  = parse_lattice_parameters(myjob['unitcell'])
      myjob['lattice_type']  = parse_lattice_type(myjob['unitcell'])
   

      myjob['xyzblob']  = parse_output_to_xyz(outfile_without_hash)
      #myjob['xyzblob'] =  parse_xyzblob(outfile_without_hash,"hello.xyz")
      myjob['cif']      = nwchem_output_to_cif_string(myjob['unitcell'],myjob['xyzblob'])
      #myjob['smiles']   = xyz2smiles(myjob['xyzblob'])
      #myjob['InChI']    = smiles2InChI(myjob['smiles'])
      myjob['InChIKey'] = xyz2InChIKey(myjob['xyzblob'])
      myjob['space_group']  = parse_space_group(outfile_without_hash)
      myjob['energy'] = parse_total_pspw_energy(outfile_without_hash)

      #myjob['cid']      = pubchem_smiles2cid(myjob['smiles'])
      #myjob['cas']      = pubchem_smiles2cas(myjob['smiles'])
      #myjob['kegg']     = pubchem_smiles2kegg(myjob['smiles'])
      #synonyms = pubchem_smiles2synonyms(myjob['smiles'])
      #InChI2 = xyz2InChI(xyzfile)
      myjob['mformula'] = xyz_molecular_formula(myjob['xyzblob'])
      #(bonding_string, covalent_string) = xyz_bonding_strings(xyzfile)

   



      #inserting = (energy<=9.0e9) and (smiles!='')
      #sitkoff  = ecd
      #honig    = ehd
      #ASA      = sum(msurface[0])
      #SAV      = sum(msurface[1])
      wannier_data = parse_wannier_centers(outfile_without_hash)
      print("wannier_data=",wannier_data)  
      if (wannier_data!=None):
         wannier_magnetization = compute_wannier_magnetization(wannier_data)
         myjob['wannier'] = wannier_data
         myjob['wannier_magnetization'] = wannier_magnetization
         print_wannier_table(wannier_data, wannier_magnetization)
         myjob['wannier_charges'] = True

      #print("DEBUG: Parsed Wannier Data =", wannier_data)  # Debugging
      #print("DEBUG: Parsed Wannier wannier magnetization =", wannier_magnetization)  # Debugging


      dly_data = parse_dly_wannier_centers(outfile_without_hash)
      print("dly_data=",dly_data)
      if ((dly_data!=None) and (len(dly_data)>0)):
         dly_magnetization = compute_wannier_magnetization(dly_data)
         myjob['dly'] = dly_data
         myjob['dly_magnetization'] = dly_magnetization
         print_dly_table(dly_data, dly_magnetization)
      


      if (len(extra_datafiles)>0):
       if  (are_all_cube_files_present(outfile_without_hash, extra_datafiles)):
         myjob['cube_files']   = parse_cube_files(outfile_without_hash)
         jjjj =  parse_cube_files(outfile_without_hash)

         alphacube =  get_full_cube_filenames(parse_cube_files(outfile_without_hash),extra_datafiles)['alpha']
         betacube =  get_full_cube_filenames(parse_cube_files(outfile_without_hash),extra_datafiles)['beta']
         totalcube =  get_full_cube_filenames(parse_cube_files(outfile_without_hash),extra_datafiles)['total']
         diffcube =  get_full_cube_filenames(parse_cube_files(outfile_without_hash),extra_datafiles)['difference']
         atom_names = extract_atom_names_from_cube(alphacube)
         
         #print("alphacube=",alphacube)
         #print("betacube=",betacube)
         #print("totalcube=",totalcube)
         #print("diffcube=",diffcube)

         cmd = bader + alphacube
         alpha_result = subprocess.check_output(cmd,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
         alpha_acf = ''
         with open("ACF.dat",'r') as ff:
            alpha_acf += ff.read()

         cmd = bader + betacube
         result = subprocess.check_output(cmd,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
         beta_acf = ''
         with open("ACF.dat",'r') as ff:
            beta_acf += ff.read()

         cmd = bader + totalcube
         result = subprocess.check_output(cmd,shell=True,stderr=subprocess.STDOUT).decode("utf-8")
         total_acf = ''
         with open("ACF.dat",'r') as ff:
            total_acf += ff.read()

         bader_alpha = extract_bader_charges(alpha_acf)
         bader_beta  = extract_bader_charges(beta_acf)
         bader_total = extract_bader_charges(total_acf)
         #print("Alpha Bader Charges:", bader_alpha)
         #print("Beta Bader Charges:", bader_beta)
         #print("Total Bader Charges:", bader_total)
         bader_magnetization = compute_bader_magnetization(bader_alpha, bader_beta,atom_names)
         myjob['bader_alpha'] = bader_alpha
         myjob['bader_beta']  = bader_beta
         myjob['bader_total'] = bader_total
         myjob['bader_magnetization'] = bader_magnetization
         myjob['bader_charges'] = True
         #print("bader magnetization:", bader_magnetization)

         print_bader_analysis(bader_alpha, bader_beta, bader_total, bader_magnetization)
         print_both_magnetization(wannier_data, wannier_magnetization, bader_magnetization)

         # Print Results
         #print("Bader Magnetization per Atom:")
         #for atom, (name, mag) in bader_magnetization.items():
         #    print(f"Atom {atom} ({name}): {mag:.4f}")

         


      #print("wannier=", myjob['wannier'])

      print("myjob=",myjob)

      print()
      print(" xyzblob             =",myjob['xyzblob']);
      print(" cif                 =",myjob['cif']);
      print(" unitcell            =",myjob['unitcell']);
      print(" mformula            =",myjob['mformula'])
      print(" theory                 =",myjob['theory'])
      print(" genome                 =",myjob['genome'])
      print(" datetime               =",myjob['datetime'])
      print(" k_point_grid           =",myjob['k_point_grid'])
      print(" smear_type             =",myjob['smearing_type'])
      print(" smearing_width         =",myjob['smearing_width'])
      print(" machine                =",myjob['machine'])
      print(" ncpu                   =",myjob['ncpu'])
      print(" wall_time              =",myjob['wall_time'])
      print(" pseudopotentials       =",myjob['pseudopotentials'])
      print(" material_name          =",myjob['material_name'])
      print(" lattice_parameters     =",myjob['lattice_parameters'])
      print(" lattice_type           =",myjob['lattice_type'])
      print(" space_group            =",myjob['space_group'])
      print(" basis                  =",myjob['basis'])
      print(" energy                 =",myjob['energy'])
      print(" enthalpy               =",myjob['enthalpy'])
      print(" entropy                =",myjob['entropy'])
      print(" hubbard_U              =",myjob['hubbaard_U'])
      print(" initial_magnetic_moments=",myjob['initial_magnetic_moments'])
      if (myjob['wannier_charges']):
         print(" wannier                =",myjob['wannier'])
         print(" wannier_magnetization  =",myjob['wannier_magnetization'])
      if ((dly_data!=None) and (len(dly_data)>0)):
         print(" dly                    =",myjob['dly'])
         print(" dly_magnetization      =",myjob['dly_magnetization'])
      if (myjob['bader_charges']):
         print(" bader_alpha            =",myjob['bader_alpha'])
         print(" bader_beta             =",myjob['bader_beta'])
         print(" bader_total            =",myjob['bader_total'])
         print(" bader_magnetization    =",myjob['bader_magnetization'])
      print(" jobok                  =",myjob['jobok'])
      print(" spin penalty           =",myjob['spin_penalty'])



       










##############################################################################
############################# main program ###################################
##############################################################################
usage = \
"""
Remote solid_add_nwout mysql  program

  Usage: solid_add_nwout -h hup_string -d database -t table -q requests_table -b bad_table -n nmr_table -c bad_nmr_table -m nwmachine -p nwpasswrd -z string_of_datafiles nwoutfiles

  -h hup_string="machine user password" or enter sqlite3 for sqlite3 db
  -d database = "name of database"
  -t table = "name of table"
  -q requests_table = "name of requests_table"
  -b bad_table = "name of bad_table"
  -n nmr_table = "name of nmr_table"
  -c bad_nmr_table = "name of bad_nmr_table"
  -m nwmachine = "machine:directory"
  -p nwpassrd = password for nwmachine
  -x prints this message
  -z string of extra_datafiles
  -s no resubmit

"""

#Database defaults
hup    = hup0
dbfile = dbfile0
table  = "calculations"
requests_table  = "requests"
bad_table       = "bad_calculations"
nmr_table       = "nmr_calculations"
bad_nmr_table   = "bad_nmr_calculations"
abrev_table     = "abbreviations"
aimd_table      = "aimd_calculations"
solute_table    = "solute_structures"
extra_datafiles = ''
noresubmit = False

nwmachine  = archivemachine + "/%d/%d" % (random.randint(0,99),random.randint(0,99))
nwpassword = archivepassword

a = random.randint(0,9)
b = random.randint(0,9)
c = random.randint(0,9)
d = random.randint(0,9)
e = random.randint(0,9)
nwmachine_aimd = archivemachine+"/aimd_simulations/%d/%d/%d/%d/%d/" % (a,b,c,d,e)



print()
print()
print()
print("+-------------------------------+")
print("| solid_add_nwout mysql version |")
print("+-------------------------------+")
print()
tt = time.localtime()
dd = "-%d-%d-%d-%d:%d.%d" % (tt[0],tt[1],tt[2],tt[3],tt[4],tt[5])


opts, args = getopt.getopt(sys.argv[1:], "h:d:t:q:b:n:c:m:p:z:xs")
for o, a in opts:
  if '-s' in o:
     noresubmit = True
  if '-h' in o:
     hup = a
  if '-d' in o:
     dbfile = a
  if '-t' in o:
     table = a
  if '-q' in o:
     requests_table = a
  if '-b' in o:
     bad_table = a
  if '-n' in o:
     nmr_table = a
  if '-c' in o:
     bad_nmr_table = a
  if '-m' in o:
     nwmachine = a
  if '-p' in o:
     nwpassword = a
  if '-z' in o:
     extra_datafiles = a
  if o in ("-x","--help"):
    print(usage)
    exit()

if (len(args)<1):
   print(usage)
   exit()

nwofiles  = []
for i in range(len(args)):
   nwofiles.append(args[i])


print("nwofile=",nwofiles)
print("extradatafiles=",extra_datafiles)


for outfile in nwofiles:
   insert_solid_calculation(outfile,hup,dbfile,table,bad_table,abrev_table,nwpassword,nwmachine,extra_datafiles,noresubmit)

   #nmr_blob = parse_nmrblob(outfile)
   #if (nmr_blob!=''):
   #   insert_nmr_calculation(outfile,hup,dbfile,nmr_table,bad_nmr_table,nwpassword,nwmachine)


### delete temporary wrkdir files ###
try:
   os.unlink(wrkdir + "/" + tmpsmi1)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpsmi1)

try:
   os.unlink(wrkdir + "/" + tmpsmi2)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpsmi2)

try:
   os.unlink(wrkdir + "/" + tmpsmi3)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpsmi3)

try:
   os.unlink(wrkdir + "/" + tmpxyz1)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpxyz1)

try:
   os.unlink(wrkdir + "/" + tmpxyz2)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpxyz2)

try:
   os.unlink(wrkdir + "/" + outfile99)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + outfile99)

try:
   os.unlink(wrkdir + "/" + tmpxyz99)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpxyz99)

try:
   os.unlink(wrkdir + "/" + tmpgr)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmpgr)

try:
   os.unlink(wrkdir + "/" + tmphist)
except:
   print("solid_add_nwout Failed removing "+ wrkdir + "/" + tmphist)
